{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3613jvsc74a57bd04be7a7d07737abc13ce0405d66476ee95c71ec67bbd16eb87477248084e696ea",
   "display_name": "Python 3.6.13 64-bit ('audiosp_env': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa as lr\n",
    "import numpy as np\n",
    "import numpy\n",
    "import math\n",
    "import decimal\n",
    "import soundfile as sf\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.fftpack import dct"
   ]
  },
  {
   "source": [
    "## Utility functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#params\n",
    "NUM_FILTER = 22\n",
    "SAMPLING_RATE = 16_000 # number of samples per sec\n",
    "FMIN=20 # hz\n",
    "FMAX=8000 # hz\n",
    "WINDOW_LENGTH = 0.020 # ms\n",
    "HOP_LENGTH = 0.010 # ms\n",
    "\n",
    "def get_band_filter_coeff(samplerate, f0, Q=1.0):\n",
    "    \"\"\"\n",
    "    Bandpass filter based on BLT: Cookbook formulae for audio EQ biquad filter coefficients\n",
    "    https://gist.github.com/RyanMarcus/d3386baa6b4cb1ac47f4#file-gistfile1-txt\n",
    "    \"\"\"\n",
    "    w0 = 2 * np.pi * f0 / samplerate\n",
    "    alpha = np.sin(w0) / (2 * Q)\n",
    "    a = np.zeros(3)\n",
    "    b = np.zeros(3)\n",
    "    b[0] = Q*alpha\n",
    "    b[1] = 0\n",
    "    b[2] = -Q*alpha\n",
    "    a[0] = 1 + alpha\n",
    "    a[1] = -2*np.cos(w0)\n",
    "    a[2] = 1-alpha\n",
    "    return  b, a\n",
    "\n",
    "def iir_design_first_order(band_frequency, samplerate=SAMPLING_RATE, normalize=True): # the ban frequency is the middel fre\n",
    "    b = []\n",
    "    a = []\n",
    "    for i in range(len(band_frequency)):\n",
    "        b_, a_ = get_band_filter_coeff(samplerate, band_frequency[i])\n",
    "        if(normalize):\n",
    "            b_ = b_/a_[0]           # unified\n",
    "            a_[1:] = a_[1:]/a_[0]\n",
    "            a_[0] = 1\n",
    "        b.append(b_)\n",
    "        a.append(a_)\n",
    "    return b, a\n",
    "    # Ref implementation:\n",
    "    # b, a = set_gains(b_in, a_in, alpha, gains[0])\n",
    "    # i = 0\n",
    "    # g = 0\n",
    "    # for n in range(2, len(x)):\n",
    "    #     y[n] = b[0] * x[n] + b[1] * x[n - 1] + b[2] * x[n - 2] - a[1]* y[n - 1] - a[2] * y[n - 2]\n",
    "    #     if (n % step == 0 and i < len(gains)-1):\n",
    "    #         i += 1\n",
    "    #         g = gains[i] * 0.4 + g*0.6\n",
    "    #         b, a = set_gains(b_in, a_in, alpha, g)\n",
    "    # return y\n",
    "\n",
    "def generate_filter_header(b, a, order, filename='equalizer_coeff.h'):\n",
    "    def array2str(data):\n",
    "        s = np.array2string(np.array(data).flatten(), separator=',')\n",
    "        return s.replace(\"\\n\", \"\").replace(\"\\r\", \"\").replace(' ', '').replace(',', ', ').replace('[', '{').replace(']', '}')\n",
    "    with open(filename, 'w') as file:\n",
    "        file.write(\"\\n#define NUM_FILTER \" + str(len(b)) + '\\n')\n",
    "        file.write(\"\\n#define NUM_ORDER \" +  str(order) + '\\n')\n",
    "        file.write(\"\\n#define NUM_COEFF_PAIR \" + str(order*2+1) + '\\n')\n",
    "        file.write(\"\\n#define FILTER_COEFF_A \" + array2str(a) + \"\\n\")\n",
    "        file.write(\"\\n#define FILTER_COEFF_B \" + array2str(b) + \"\\n\")\n",
    "\n",
    "def iir_design(band_frequency, samplerate=SAMPLING_RATE, order=1): # the ban frequency is the middel fre\n",
    "    b = []\n",
    "    a = []\n",
    "    fre = band_frequency / (samplerate/2)\n",
    "    for i in range(1, len(band_frequency)-1):\n",
    "        b_, a_ = signal.iirfilter(order, [fre[i] - (fre[i]-fre[i-1])/2, fre[i]+ (fre[i+1]-fre[i])/2],\n",
    "                                  btype='bandpass', output='ba')\n",
    "        # b_, a_ = signal.iirfilter(order, [fre[i-1], fre[i+1]-0.001],\n",
    "        #                            btype='bandpass', output='ba')\n",
    "        # b_, a_ = signal.cheby1(order, 1, [fre[i] - (fre[i]-fre[i-1])/2, fre[i]+ (fre[i+1]-fre[i])/2],\n",
    "        #                           btype='bandpass', output='ba')\n",
    "        b.append(b_)\n",
    "        a.append(a_)\n",
    "    return b, a\n",
    "\n",
    "def fir_design(band_frequency, samplerate=SAMPLING_RATE, order=51):\n",
    "    from scipy import signal\n",
    "    b = []\n",
    "    fre = band_frequency / (samplerate/2)\n",
    "    for i in range(1, len(band_frequency)-1):\n",
    "        b.append(signal.firwin(order, [fre[i] - (fre[i]-fre[i-1])/2, fre[i]+ (fre[i+1]-fre[i])/2], pass_zero='bandpass'))\n",
    "    return b\n",
    "\n",
    "def get_mel_scale(nfilt=NUM_FILTER, samplerate=SAMPLING_RATE, lowfreq=FMIN, highfreq=FMAX):\n",
    "    highfreq = highfreq or samplerate / 2\n",
    "    assert highfreq <= samplerate / 2, \"highfreq is greater than samplerate/2\"\n",
    "    # compute points evenly spaced in mels\n",
    "    lowmel = lr.hz_to_mel(lowfreq)\n",
    "    highmel = lr.hz_to_mel(highfreq)\n",
    "    melpoints = np.linspace(lowmel, highmel, nfilt + 2)\n",
    "    return melpoints\n",
    "\n",
    "def bandpass_filter_fir(sig, b_in, a_in, step, gains):\n",
    "    from scipy import signal\n",
    "    x = sig\n",
    "    y = np.zeros(len(x))\n",
    "    state = np.zeros(len(b_in)-1)\n",
    "    g=0\n",
    "    for n in range(0, len(gains)):\n",
    "        g = max(0.8*g, gains[n])    # pre RNNoise paper https://arxiv.org/pdf/1709.08243.pdf\n",
    "        b = b_in * g\n",
    "        filtered, state = signal.lfilter(b, 1, x[n*step: min((n+1)*step, len(x))], zi=state)\n",
    "        y[n*step: min((n+1)*step, len(x))] = filtered\n",
    "    return y\n",
    "\n",
    "def bandpass_filter_iir(sig, b_in, a_in, step, gains):\n",
    "    from scipy import signal\n",
    "    x = sig\n",
    "    y = np.zeros(len(x))\n",
    "    state = np.zeros(len(b_in)-1)\n",
    "    g=0\n",
    "    for n in range(0, len(gains)):\n",
    "        g = max(0.6*g, gains[n])    # r=0.6 pre RNNoise paper https://arxiv.org/pdf/1709.08243.pdf\n",
    "        b = b_in*g\n",
    "        a = a_in\n",
    "        filtered, state = signal.lfilter(b, a, x[n*step: min((n+1)*step, len(x))], zi=state)\n",
    "        y[n*step: min((n+1)*step, len(x))] = filtered\n",
    "    return y\n",
    "\n",
    "\n",
    "def plot_frequency_respond(b, a=None, fs=SAMPLING_RATE):\n",
    "    a = a if len(a) == len(b)  else np.ones(len(b))\n",
    "    for i in range(len(b)):\n",
    "        w, h = signal.freqz(b[i], a[i])\n",
    "        plt.plot(w*0.15915494327*fs, 20 * np.log10(np.maximum(abs(h), 1e-5)), 'b')\n",
    "    plt.title('Digital filter frequency response')\n",
    "    plt.ylabel('Amplitude [dB]', color='b')\n",
    "    plt.xlabel('Frequency [Hz]')\n",
    "    plt.show()\n",
    "\n",
    "def noise_suppressed_example(example_number, snr, plot=False):\n",
    "    \"\"\"\n",
    "    In this example, we demonstrate how we suppress noise using dynamic gains in an audio equalizer [EQ].\n",
    "    The basic idea is we use the clean to noisy energy ratio of each frequency band as the gain of suppression.\n",
    "    It is done in a very small windows (500 point = 31.25ms) so that it can respone very quickly.\n",
    "    Then we apply these gains to an equalizer (a set of parallel bandpass filter). The gains are changing very fast\n",
    "    so the noise will be suppressed when it is detected.\n",
    "\n",
    "    This is also the principle that how do we generate the truth gains for the training data (y_train).\n",
    "    \"\"\"\n",
    "    # change here to select the file and its noise mixing level.\n",
    "    test_num = example_number          # which file\n",
    "    test_noise_level = snr  # noise level in db, selected from 0, 10, 20, depeneded on dataset\n",
    "\n",
    "    # change here to select the file and its noise mixing level.\n",
    "    clean_file = \"MS-SNSD/CleanSpeech_training/clnsp\" + str(test_num) + \".wav\"\n",
    "    noisy_file = \"MS-SNSD/NoisySpeech_training/noisy\"+str(test_num)+\"_SNRdb_\"+str(test_noise_level)+\".0_clnsp\"+str(test_num) +\".wav\"\n",
    "\n",
    "    (clean_sig, rate) = lr.load(clean_file, sr=SAMPLING_RATE)\n",
    "    (noisy_sig, rate) = lr.load(noisy_file, sr=SAMPLING_RATE)\n",
    "    # clean_sig = clean_sig/32768\n",
    "    # noisy_sig = noisy_sig/32768\n",
    "\n",
    "    # Calculate the energy of each frequency bands\n",
    "    clean_band_eng, _ = fbank(clean_sig, rate, winlen=WINDOW_LENGTH, winstep=HOP_LENGTH, nfilt=NUM_FILTER, nfft=512, lowfreq=FMIN, highfreq=FMAX, preemph=0)\n",
    "    noisy_band_eng, _ = fbank(noisy_sig, rate, winlen=WINDOW_LENGTH, winstep=HOP_LENGTH, nfilt=NUM_FILTER, nfft=512, lowfreq=FMIN, highfreq=FMAX, preemph=0)\n",
    "    # gains\n",
    "    gains = np.sqrt(clean_band_eng / noisy_band_eng)\n",
    "    if(plot):\n",
    "        plt.title(\"Gains\")\n",
    "        plt.plot(gains[:, :10])\n",
    "        plt.show()\n",
    "\n",
    "    # convert mel scale back to frequency band\n",
    "    mel_freqs = lr.mel_frequencies(n_mels=NUM_FILTER, fmin=FMIN, fmax=FMAX)\n",
    "    band_frequency = mel_freqs[1:-1] # the middle point of each band\n",
    "    print('band frequency', band_frequency)\n",
    "\n",
    "    # the noisy audio now pass to a set of parallel band pass filter.\n",
    "    # which performed like an audio equalizer [EQ]\n",
    "    # the different is we will change the gains of each band very quickly so that we suppress the noise while keeping the speech.\n",
    "    # design our band pass filter for each band in the equalizer.\n",
    "    # becasue the frequency band is overlapping, we need to reduce the signal to avoid overflow when converting back to int16.\n",
    "\n",
    "    print(\"denoising using IIR filter\")\n",
    "    b, a = iir_design(mel_freqs, SAMPLING_RATE)\n",
    "    if plot:\n",
    "        plot_frequency_respond(b, a)\n",
    "    print(\"b\", b)\n",
    "    print(\"a\", a)\n",
    "    step = int(HOP_LENGTH * SAMPLING_RATE)\n",
    "    print(\"audio process step:\", step)\n",
    "    filtered_signal = np.zeros(len(noisy_sig))\n",
    "    for i in range(len(b)):\n",
    "        filtered_signal += bandpass_filter_iir(noisy_sig, b[i].copy(), a[i].copy(), step, gains[:, i])\n",
    "        print(\"filtering with frequency: \", band_frequency[i])\n",
    "    filtered_signal = filtered_signal * 0.6\n",
    "\n",
    "    filtered_signal = np.clip(filtered_signal, -1, 1)\n",
    "    sf.write(\"_filtered_sample.wav\", np.asarray(filtered_signal * 32767, dtype=np.int16), SAMPLING_RATE)\n",
    "    sf.write(\"_noisy_sample.wav\", np.asarray(noisy_sig * 32767, dtype=np.int16), SAMPLING_RATE)\n",
    "    sf.write(\"_clean_sample.wav\", np.asarray(clean_sig * 32767, dtype=np.int16), SAMPLING_RATE)\n",
    "    print(\"filtered signal is saved to:\", \"_filtered_sample.wav\")\n",
    "    print(\"noisy signal is saved to:\", \"_noisy_sample.wav\")\n",
    "    print(\"clean signal is saved to:\", \"_clean_sample.wav\")\n",
    "\n",
    "\n",
    "def generate_data(path, vad_active_delay=0.07, vad_threshold=1e-1, random_volume=True, winlen=WINDOW_LENGTH, winstep=HOP_LENGTH,\n",
    "                  numcep=13, nfilt=NUM_FILTER, nfft=512, lowfreq=FMIN, highfreq=FMAX, winfunc=np.hanning, ceplifter=0,\n",
    "                  preemph=0.97, appendEnergy=True):\n",
    "    \"\"\"\n",
    "    vad_filter_size: number of winstep for filter. if one of the point is active, the first size/2 and last size/2 will be actived\n",
    "    Larger size will have better cover to the speech, but will bring none-speech moments\n",
    "    please refer to python_speech_features.mfcc for other parameters\n",
    "    \"\"\"\n",
    "    mfcc_data = []\n",
    "    filename_label = []\n",
    "    total_energy = []\n",
    "    band_energy = []\n",
    "    vad = []\n",
    "    files = os.listdir(path)\n",
    "    for f in files:\n",
    "        filename = f\n",
    "        if ('wav' not in filename):\n",
    "            continue\n",
    "        (sig, rate) = lr.load(path+'/'+f, sr=SAMPLING_RATE)\n",
    "        # convert file to [-1, 1)\n",
    "        # sig = sig/32768\n",
    "\n",
    "        # calculate the energy per band, this was one of the step in mfcc but taked out\n",
    "        band_eng, total_eng = fbank(sig, rate, winlen=winlen, winstep=winstep, nfilt=nfilt, nfft=nfft, lowfreq=lowfreq,\n",
    "                                   highfreq=highfreq, preemph=preemph, winfunc=winfunc)\n",
    "\n",
    "        # for the mfcc, because we are not normalizing them,\n",
    "        # so we randomize the volume to simulate the real life voice record.\n",
    "        if(random_volume):\n",
    "            sig = sig * np.random.uniform(0.8, 1)\n",
    "\n",
    "        # calculate mfcc features\n",
    "        mfcc_feat = mfcc(sig, rate, winlen=winlen, winstep=winstep, numcep=numcep, nfilt=nfilt, nfft=nfft,\n",
    "                         lowfreq=lowfreq, highfreq=highfreq, winfunc=winfunc, ceplifter=ceplifter, preemph=preemph,\n",
    "                         appendEnergy=appendEnergy)\n",
    "\n",
    "        # voice active detections, only valid with clean speech. Detected by total energy vs threshold.\n",
    "        v = (total_eng > vad_threshold).astype(int)\n",
    "        vad_delay = int(vad_active_delay*(rate*winstep))\n",
    "        conv_win = np.concatenate([np.zeros(vad_delay), np.ones(vad_delay)]) # delay the VAD for a vad_active_delay second\n",
    "        v = np.convolve(v, conv_win, mode='same')\n",
    "        v = (v > 0).astype(int)\n",
    "\n",
    "        total_energy.append(total_eng)\n",
    "        band_energy.append(band_eng)\n",
    "        vad.append(v)\n",
    "        mfcc_data.append(mfcc_feat.astype('float32'))\n",
    "        filename_label.append(filename)\n",
    "    return mfcc_data, filename_label, total_energy, vad, band_energy\n",
    "\n",
    "\n",
    "def fbank(signal,samplerate=SAMPLING_RATE,winlen=WINDOW_LENGTH,winstep=HOP_LENGTH,\n",
    "          nfilt=NUM_FILTER,nfft=512,lowfreq=FMIN,highfreq=FMAX,preemph=0.97,\n",
    "          winfunc=lambda x:numpy.ones((x,))):\n",
    "    \"\"\"Compute Mel-filterbank energy features from an audio signal.\n",
    "\n",
    "    :param signal: the audio signal from which to compute features. Should be an N*1 array\n",
    "    :param samplerate: the sample rate of the signal we are working with, in Hz.\n",
    "    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
    "    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
    "    :param nfilt: the number of filters in the filterbank, default 26.\n",
    "    :param nfft: the FFT size. Default is 512.\n",
    "    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n",
    "    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n",
    "    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n",
    "    :returns: 2 values. The first is a numpy array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector. The\n",
    "        second return value is the energy in each frame (total energy, unwindowed)\n",
    "    \"\"\"\n",
    "    highfreq= highfreq or samplerate/2\n",
    "    signal = preemphasis(signal, preemph)\n",
    "    frames = framesig(signal, winlen*samplerate, winstep*samplerate, winfunc)\n",
    "    pspec = powspec(frames, nfft)\n",
    "    energy = numpy.sum(pspec,1) # this stores the total energy in each frame\n",
    "    energy = numpy.where(energy == 0,numpy.finfo(float).eps,energy) # if energy is zero, we get problems with log\n",
    "\n",
    "    fb = get_filterbanks(nfilt,nfft,samplerate,lowfreq,highfreq)\n",
    "    feat = numpy.dot(pspec,fb.T) # compute the filterbank energies\n",
    "    feat = numpy.where(feat == 0,numpy.finfo(float).eps,feat) # if feat is zero, we get problems with log\n",
    "    return feat,energy\n",
    "\n",
    "\n",
    "def get_filterbanks(nfilt=NUM_FILTER,nfft=512,samplerate=SAMPLING_RATE,lowfreq=FMIN,highfreq=FMAX):\n",
    "    \"\"\"Compute a Mel-filterbank. The filters are stored in the rows, the columns correspond\n",
    "    to fft bins. The filters are returned as an array of size nfilt * (nfft/2 + 1)\n",
    "\n",
    "    :param nfilt: the number of filters in the filterbank, default 20.\n",
    "    :param nfft: the FFT size. Default is 512.\n",
    "    :param samplerate: the sample rate of the signal we are working with, in Hz. Affects mel spacing.\n",
    "    :param lowfreq: lowest band edge of mel filters, default 0 Hz\n",
    "    :param highfreq: highest band edge of mel filters, default samplerate/2\n",
    "    :returns: A numpy array of size nfilt * (nfft/2 + 1) containing filterbank. Each row holds 1 filter.\n",
    "    \"\"\"\n",
    "    highfreq= highfreq or samplerate/2\n",
    "    assert highfreq <= samplerate/2, \"highfreq is greater than samplerate/2\"\n",
    "\n",
    "    # compute points evenly spaced in mels\n",
    "    lowmel = lr.hz_to_mel(lowfreq)\n",
    "    highmel = lr.hz_to_mel(highfreq)\n",
    "    melpoints = numpy.linspace(lowmel,highmel,nfilt+2)\n",
    "    # our points are in Hz, but we use fft bins, so we have to convert\n",
    "    #  from Hz to fft bin number\n",
    "    bin = numpy.floor((nfft+1)*lr.mel_to_hz(melpoints)/samplerate)\n",
    "\n",
    "    fbank = numpy.zeros([nfilt,nfft//2+1])\n",
    "    for j in range(0,nfilt):\n",
    "        for i in range(int(bin[j]), int(bin[j+1])):\n",
    "            fbank[j,i] = (i - bin[j]) / (bin[j+1]-bin[j])\n",
    "        for i in range(int(bin[j+1]), int(bin[j+2])):\n",
    "            fbank[j,i] = (bin[j+2]-i) / (bin[j+2]-bin[j+1])\n",
    "    return fbank\n",
    "\n",
    "\n",
    "def lifter(cepstra, L=22):\n",
    "    \"\"\"Apply a cepstral lifter the the matrix of cepstra. This has the effect of increasing the\n",
    "    magnitude of the high frequency DCT coeffs.\n",
    "\n",
    "    :param cepstra: the matrix of mel-cepstra, will be numframes * numcep in size.\n",
    "    :param L: the liftering coefficient to use. Default is 22. L <= 0 disables lifter.\n",
    "    \"\"\"\n",
    "    if L > 0:\n",
    "        nframes,ncoeff = numpy.shape(cepstra)\n",
    "        n = numpy.arange(ncoeff)\n",
    "        lift = 1 + (L/2.)*numpy.sin(numpy.pi*n/L)\n",
    "        return lift*cepstra\n",
    "    else:\n",
    "        # values of L <= 0, do nothing\n",
    "        return cepstra\n",
    "\n",
    "\n",
    "#signal processing\n",
    "def powspec(frames, NFFT):\n",
    "    \"\"\"Compute the power spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n",
    "\n",
    "    :param frames: the array of frames. Each row is a frame.\n",
    "    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n",
    "    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the power spectrum of the corresponding frame.\n",
    "    \"\"\"\n",
    "    return 1.0 / NFFT * numpy.square(magspec(frames, NFFT))\n",
    "    #return 1.0 / NFFT * magspec(frames, NFFT)\n",
    "\n",
    "\n",
    "def preemphasis(signal, coeff=0.95):\n",
    "    \"\"\"perform preemphasis on the input signal.\n",
    "\n",
    "    :param signal: The signal to filter.\n",
    "    :param coeff: The preemphasis coefficient. 0 is no filter, default is 0.95.\n",
    "    :returns: the filtered signal.\n",
    "    \"\"\"\n",
    "    return numpy.append(signal[0], signal[1:] - coeff * signal[:-1])\n",
    "\n",
    "\n",
    "def framesig(sig, frame_len, frame_step, winfunc=lambda x: numpy.ones((x,)), stride_trick=True):\n",
    "    \"\"\"Frame a signal into overlapping frames.\n",
    "\n",
    "    :param sig: the audio signal to frame.\n",
    "    :param frame_len: length of each frame measured in samples.\n",
    "    :param frame_step: number of samples after the start of the previous frame that the next frame should begin.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied.\n",
    "    :param stride_trick: use stride trick to compute the rolling window and window multiplication faster\n",
    "    :returns: an array of frames. Size is NUMFRAMES by frame_len.\n",
    "    \"\"\"\n",
    "    slen = len(sig)\n",
    "    frame_len = int(round_half_up(frame_len))\n",
    "    frame_step = int(round_half_up(frame_step))\n",
    "    if slen <= frame_len:\n",
    "        numframes = 1\n",
    "    else:\n",
    "        numframes = 1 + int(math.ceil((1.0 * slen - frame_len) / frame_step))\n",
    "\n",
    "    padlen = int((numframes - 1) * frame_step + frame_len)\n",
    "\n",
    "    zeros = numpy.zeros((padlen - slen,))\n",
    "    padsignal = numpy.concatenate((sig, zeros))\n",
    "    if stride_trick:\n",
    "        win = winfunc(frame_len)\n",
    "        frames = rolling_window(padsignal, window=frame_len, step=frame_step)\n",
    "    else:\n",
    "        indices = numpy.tile(numpy.arange(0, frame_len), (numframes, 1)) + numpy.tile(\n",
    "            numpy.arange(0, numframes * frame_step, frame_step), (frame_len, 1)).T\n",
    "        indices = numpy.array(indices, dtype=numpy.int32)\n",
    "        frames = padsignal[indices]\n",
    "        win = numpy.tile(winfunc(frame_len), (numframes, 1))\n",
    "\n",
    "    return frames * win\n",
    "\n",
    "\n",
    "def round_half_up(number):\n",
    "    return int(decimal.Decimal(number).quantize(decimal.Decimal('1'), rounding=decimal.ROUND_HALF_UP))\n",
    "\n",
    "\n",
    "def rolling_window(a, window, step=1):\n",
    "    # http://ellisvalentiner.com/post/2017-03-21-np-strides-trick\n",
    "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "    strides = a.strides + (a.strides[-1],)\n",
    "    return numpy.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)[::step]\n",
    "\n",
    "\n",
    "def magspec(frames, NFFT):\n",
    "    \"\"\"Compute the magnitude spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n",
    "\n",
    "    :param frames: the array of frames. Each row is a frame.\n",
    "    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n",
    "    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the magnitude spectrum of the corresponding frame.\n",
    "    \"\"\"\n",
    "    if numpy.shape(frames)[1] > NFFT:\n",
    "        logging.warn(\n",
    "            'frame length (%d) is greater than FFT size (%d), frame will be truncated. Increase NFFT to avoid.',\n",
    "            numpy.shape(frames)[1], NFFT)\n",
    "    complex_spec = numpy.fft.rfft(frames, NFFT)\n",
    "    return numpy.absolute(complex_spec)\n",
    "\n",
    "\n",
    "def calculate_nfft(samplerate=SAMPLING_RATE, winlen=WINDOW_LENGTH):\n",
    "    \"\"\"Calculates the FFT size as a power of two greater than or equal to\n",
    "    the number of samples in a single window length.\n",
    "    \n",
    "    Having an FFT less than the window length loses precision by dropping\n",
    "    many of the samples; a longer FFT than the window allows zero-padding\n",
    "    of the FFT buffer which is neutral in terms of frequency domain conversion.\n",
    "\n",
    "    :param samplerate: The sample rate of the signal we are working with, in Hz.\n",
    "    :param winlen: The length of the analysis window in seconds.\n",
    "    \"\"\"\n",
    "    window_length_samples = winlen * samplerate\n",
    "    nfft = 1\n",
    "    while nfft < window_length_samples:\n",
    "        nfft *= 2\n",
    "    return nfft\n",
    "\n",
    "def mfcc(signal,samplerate=SAMPLING_RATE,winlen=WINDOW_LENGTH,winstep=HOP_LENGTH,numcep=13,\n",
    "         nfilt=NUM_FILTER,nfft=None,lowfreq=FMIN,highfreq=FMAX,preemph=0.97,ceplifter=22,appendEnergy=True,\n",
    "         winfunc=lambda x:numpy.ones((x,))):\n",
    "    \"\"\"Compute MFCC features from an audio signal.\n",
    "\n",
    "    :param signal: the audio signal from which to compute features. Should be an N*1 array\n",
    "    :param samplerate: the sample rate of the signal we are working with, in Hz.\n",
    "    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
    "    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
    "    :param numcep: the number of cepstrum to return, default 13\n",
    "    :param nfilt: the number of filters in the filterbank, default 26.\n",
    "    :param nfft: the FFT size. Default is None, which uses the calculate_nfft function to choose the smallest size that does not drop sample data.\n",
    "    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n",
    "    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n",
    "    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n",
    "    :param ceplifter: apply a lifter to final cepstral coefficients. 0 is no lifter. Default is 22.\n",
    "    :param appendEnergy: if this is true, the zeroth cepstral coefficient is replaced with the log of the total frame energy.\n",
    "    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n",
    "    :returns: A numpy array of size (NUMFRAMES by numcep) containing features. Each row holds 1 feature vector.\n",
    "    \"\"\"\n",
    "    nfft = nfft or calculate_nfft(samplerate, winlen)\n",
    "    feat,energy = fbank(signal,samplerate,winlen,winstep,nfilt,nfft,lowfreq,highfreq,preemph,winfunc)\n",
    "    feat = numpy.log(feat)\n",
    "    feat = dct(feat, type=2, axis=1, norm='ortho')[:,:numcep]\n",
    "    feat = lifter(feat,ceplifter)\n",
    "    if appendEnergy: feat[:,0] = numpy.log(energy) # replace first cepstral coefficient with log of frame energy\n",
    "    return feat"
   ]
  },
  {
   "source": [
    "## Dataset generation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "band frequency [ 162.68457293  305.36914585  448.05371878  590.73829171  733.42286463\n",
      "  876.10743756 1019.56876841 1181.19546531 1368.44396424 1585.37595027\n",
      " 1836.69698531 2127.85857846 2465.1764369  2855.96746258 3308.70846614\n",
      " 3833.22004097 4440.87958576 5144.86809638 5960.45608037 6905.33479586]\n",
      "denoising using IIR filter\n",
      "b [array([ 0.02725948,  0.        , -0.02725948]), array([ 0.02725948,  0.        , -0.02725948]), array([ 0.02725948,  0.        , -0.02725948]), array([ 0.02725948,  0.        , -0.02725948]), array([ 0.02725948,  0.        , -0.02725948]), array([ 0.02733169,  0.        , -0.02733169]), array([ 0.02908936,  0.        , -0.02908936]), array([ 0.033129,  0.      , -0.033129]), array([ 0.03818517,  0.        , -0.03818517]), array([ 0.04397984,  0.        , -0.04397984]), array([ 0.05061055,  0.        , -0.05061055]), array([ 0.05818464,  0.        , -0.05818464]), array([ 0.06681939,  0.        , -0.06681939]), array([ 0.07664186,  0.        , -0.07664186]), array([ 0.08778851,  0.        , -0.08778851]), array([ 0.10040444,  0.        , -0.10040444]), array([ 0.11464251,  0.        , -0.11464251]), array([ 0.13066214,  0.        , -0.13066214]), array([ 0.14862834,  0.        , -0.14862834]), array([ 0.16871117,  0.        , -0.16871117])]\n",
      "a [array([ 1.        , -1.94227441,  0.94548104]), array([ 1.        , -1.93226769,  0.94548104]), array([ 1.        , -1.91619602,  0.94548104]), array([ 1.        , -1.89410984,  0.94548104]), array([ 1.        , -1.86607848,  0.94548104]), array([ 1.        , -1.83200777,  0.94533662]), array([ 1.        , -1.78769474,  0.94182127]), array([ 1.        , -1.7282445 ,  0.93374199]), array([ 1.        , -1.65091577,  0.92362966]), array([ 1.        , -1.55116741,  0.91204033]), array([ 1.        , -1.42302522,  0.89877891]), array([ 1.        , -1.25945442,  0.88363072]), array([ 1.        , -1.05262073,  0.86636122]), array([ 1.        , -0.79461946,  0.84671627]), array([ 1.        , -0.47902108,  0.82442299]), array([ 1.        , -0.1037336 ,  0.79919111]), array([1.        , 0.32420574, 0.77071498]), array([1.        , 0.78140998, 0.73867572]), array([1.        , 1.21875994, 0.70274332]), array([1.        , 1.55235404, 0.66257766])]\n",
      "audio process step: 160\n",
      "filtering with frequency:  162.68457292674594\n",
      "filtering with frequency:  305.3691458534919\n",
      "filtering with frequency:  448.05371878023783\n",
      "filtering with frequency:  590.7382917069838\n",
      "filtering with frequency:  733.4228646337298\n",
      "filtering with frequency:  876.1074375604758\n",
      "filtering with frequency:  1019.5687684121317\n",
      "filtering with frequency:  1181.1954653062555\n",
      "filtering with frequency:  1368.4439642388913\n",
      "filtering with frequency:  1585.375950267741\n",
      "filtering with frequency:  1836.6969853130008\n",
      "filtering with frequency:  2127.858578457779\n",
      "filtering with frequency:  2465.176436898629\n",
      "filtering with frequency:  2855.967462576746\n",
      "filtering with frequency:  3308.7084661406966\n",
      "filtering with frequency:  3833.2200409712977\n",
      "filtering with frequency:  4440.879585756524\n",
      "filtering with frequency:  5144.868096377746\n",
      "filtering with frequency:  5960.456080372724\n",
      "filtering with frequency:  6905.334795864844\n",
      "filtered signal is saved to: _filtered_sample.wav\n",
      "noisy signal is saved to: _noisy_sample.wav\n",
      "clean signal is saved to: _clean_sample.wav\n",
      "Reading noisy and clean speech files...\n",
      "generating clean speech MFCC...\n",
      "generating noisy speech MFCC...\n",
      "generating noisy MFCC...\n",
      "Processing training data\n",
      "C:\\Users\\Adam\\anaconda3\\envs\\audiosp_env\\lib\\site-packages\\numpy\\core\\_asarray.py:136: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order, subok=True)\n",
      "Dataset generation has been saved to: dataset.npz\n"
     ]
    }
   ],
   "source": [
    "# This example will generate 2 files, noisy speech and noise suppressed speech.\n",
    "# You might open them with your player to get a feeling ot what does it sound like.\n",
    "# It give you an idea that how does this energy based noise suppression work.\n",
    "noise_suppressed_example(example_number=6, snr=20)\n",
    "\n",
    "# change this will change the whole system, including equalizer and RNN\n",
    "# it set: number of filter in equalizer, number of mfcc feature, and number of RNN output.\n",
    "# choose from 10 ~ 30.\n",
    "# num_filter = 20\n",
    "# sampling_rate = 16_000\n",
    "# fmin=20\n",
    "# fmax=8000\n",
    "\n",
    "\n",
    "# generate filter coefficient\n",
    "mel_freqs = lr.mel_frequencies(n_mels=NUM_FILTER, fmin=FMIN, fmax=FMAX)\n",
    "b, a = iir_design(mel_freqs, SAMPLING_RATE, order=1) # >2 order will not stable with only float32 accuracy in C.\n",
    "# plot frequency respond\n",
    "#plot_frequency_respond(b, a)\n",
    "\n",
    "print('Reading noisy and clean speech files...')\n",
    "# dataset generation start from here:\n",
    "# energy thresehold for voice activivity detection in clean speech.\n",
    "vad_energy_threashold = 0.1\n",
    "\n",
    "noisy_speech_dir = 'MS-SNSD/NoisySpeech_training'\n",
    "clean_speech_dir = 'MS-SNSD/CleanSpeech_training'\n",
    "noise_dir = 'MS-SNSD/Noise_training'\n",
    "\n",
    "# clean sound, mfcc, and vad\n",
    "print('generating clean speech MFCC...')\n",
    "clean_speech_mfcc, clean_file_label, total_energy, vad, clnsp_band_energy = \\\n",
    "    generate_data(clean_speech_dir, nfilt=NUM_FILTER, numcep=NUM_FILTER, appendEnergy=True, preemph=0, vad_threshold=vad_energy_threashold)\n",
    "\n",
    "# add noise to clean speech, then generate the noise MFCC\n",
    "print('generating noisy speech MFCC...')\n",
    "noisy_speech_mfcc, noisy_file_label, _, _ , noisy_band_energy= \\\n",
    "    generate_data(noisy_speech_dir, nfilt=NUM_FILTER, numcep=NUM_FILTER, appendEnergy=True, preemph=0, vad_threshold=vad_energy_threashold)\n",
    "\n",
    "# MFCC for noise only\n",
    "print('generating noisy MFCC...')\n",
    "noise_only_mfcc, noise_only_label, _, _ , noise_band_energy= \\\n",
    "    generate_data(noise_dir, random_volume=False, nfilt=NUM_FILTER, numcep=NUM_FILTER, appendEnergy=True, preemph=0)\n",
    "\n",
    "# plt.plot(vad[5], label='voice active')\n",
    "# plt.plot(total_energy[5], label='energy')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# combine them together\n",
    "clnsp_mfcc = []\n",
    "noisy_mfcc = []\n",
    "noise_mfcc = []\n",
    "voice_active = []\n",
    "gains_array = []\n",
    "\n",
    "print('Processing training data')\n",
    "for idx_nosiy, label in enumerate(noisy_file_label):\n",
    "    # get file encode from file name e.g. \"noisy614_SNRdb_30.0_clnsp614.wav\"\n",
    "    nums = re.findall(r'\\d+', label)\n",
    "    file_code = nums[0]\n",
    "    db_code = nums[1]\n",
    "\n",
    "    # get clean sound name\n",
    "    idx_clnsp = clean_file_label.index('clnsp'+str(file_code)+'.wav')\n",
    "\n",
    "    # truth gains y_train\n",
    "    gains = np.sqrt(clnsp_band_energy[idx_clnsp]/ noisy_band_energy[idx_nosiy])\n",
    "    #gains = clnsp_band_energy[idx_clnsp] / noisy_band_energy[idx_nosiy]\n",
    "    gains = np.clip(gains, 0, 1)\n",
    "\n",
    "    # experimential, suppress the gains when there is no voice detected\n",
    "    #gains[vad[idx_clnsp] < 1] = gains[vad[idx_clnsp] < 1] / 10\n",
    "    # g = np.swapaxes(gains, 0, 1)\n",
    "    # plt.imshow(g, interpolation='nearest', origin='lower', aspect='auto')\n",
    "    # plt.show()\n",
    "\n",
    "    # get all data needed\n",
    "    voice_active.append(vad[idx_clnsp])\n",
    "    clnsp_mfcc.append(clean_speech_mfcc[idx_clnsp])\n",
    "    noisy_mfcc.append(noisy_speech_mfcc[idx_nosiy])\n",
    "    noise_mfcc.append(noise_only_mfcc[idx_nosiy]) # noise has the same index as noisy speech\n",
    "    gains_array.append(gains)\n",
    "\n",
    "    #>>> Uncomment to plot the MFCC image\n",
    "    # mfcc_feat1 = np.swapaxes(clean_speech_mfcc[idx_clnsp], 0, 1)\n",
    "    # mfcc_feat2 = np.swapaxes(noisy_speech_mfcc[idx_nosiy], 0, 1)\n",
    "    # fig, ax = plt.subplots(2)\n",
    "    # ax[0].set_title('MFCC Audio:' + str(idx_clnsp))\n",
    "    # ax[0].imshow(mfcc_feat1, origin='lower', aspect='auto', vmin=-8, vmax=8)\n",
    "    # ax[1].imshow(mfcc_feat2, origin='lower', aspect='auto', vmin=-8, vmax=8)\n",
    "    # plt.show()\n",
    "\n",
    "# save the dataset.\n",
    "np.savez(\"dataset_neighbor.npz\", clnsp_mfcc=clnsp_mfcc, noisy_mfcc=noisy_mfcc, noise_mfcc=noise_mfcc, vad=voice_active, gains=gains_array)\n",
    "print(\"Dataset generation has been saved to:\", \"dataset_neighbor.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}