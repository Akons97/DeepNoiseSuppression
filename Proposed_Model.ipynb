{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proposed Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18BbzCdTXOktHJDeBpKvs2578KuFeaId-",
      "authorship_tag": "ABX9TyNGKKWKcf0b5x5pG6WcW1Rl",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Akons97/DeepNoiseSuppression/blob/main/Proposed_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4URnFv-PNGff"
      },
      "source": [
        "import decimal\n",
        "\n",
        "import numpy\n",
        "import math\n",
        "import logging\n",
        "\n",
        "\n",
        "def round_half_up(number):\n",
        "    return int(decimal.Decimal(number).quantize(decimal.Decimal('1'), rounding=decimal.ROUND_HALF_UP))\n",
        "\n",
        "\n",
        "def rolling_window(a, window, step=1):\n",
        "    # http://ellisvalentiner.com/post/2017-03-21-np-strides-trick\n",
        "    shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
        "    strides = a.strides + (a.strides[-1],)\n",
        "    return numpy.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)[::step]\n",
        "\n",
        "\n",
        "def framesig(sig, frame_len, frame_step, winfunc=lambda x: numpy.ones((x,)), stride_trick=True):\n",
        "    \"\"\"Frame a signal into overlapping frames.\n",
        "\n",
        "    :param sig: the audio signal to frame.\n",
        "    :param frame_len: length of each frame measured in samples.\n",
        "    :param frame_step: number of samples after the start of the previous frame that the next frame should begin.\n",
        "    :param winfunc: the analysis window to apply to each frame. By default no window is applied.\n",
        "    :param stride_trick: use stride trick to compute the rolling window and window multiplication faster\n",
        "    :returns: an array of frames. Size is NUMFRAMES by frame_len.\n",
        "    \"\"\"\n",
        "    slen = len(sig)\n",
        "    frame_len = int(round_half_up(frame_len))\n",
        "    frame_step = int(round_half_up(frame_step))\n",
        "    if slen <= frame_len:\n",
        "        numframes = 1\n",
        "    else:\n",
        "        numframes = 1 + int(math.ceil((1.0 * slen - frame_len) / frame_step))\n",
        "\n",
        "    padlen = int((numframes - 1) * frame_step + frame_len)\n",
        "\n",
        "    zeros = numpy.zeros((padlen - slen,))\n",
        "    padsignal = numpy.concatenate((sig, zeros))\n",
        "    if stride_trick:\n",
        "        win = winfunc(frame_len)\n",
        "        frames = rolling_window(padsignal, window=frame_len, step=frame_step)\n",
        "    else:\n",
        "        indices = numpy.tile(numpy.arange(0, frame_len), (numframes, 1)) + numpy.tile(\n",
        "            numpy.arange(0, numframes * frame_step, frame_step), (frame_len, 1)).T\n",
        "        indices = numpy.array(indices, dtype=numpy.int32)\n",
        "        frames = padsignal[indices]\n",
        "        win = numpy.tile(winfunc(frame_len), (numframes, 1))\n",
        "\n",
        "    return frames * win\n",
        "\n",
        "\n",
        "def deframesig(frames, siglen, frame_len, frame_step, winfunc=lambda x: numpy.ones((x,))):\n",
        "    \"\"\"Does overlap-add procedure to undo the action of framesig.\n",
        "\n",
        "    :param frames: the array of frames.\n",
        "    :param siglen: the length of the desired signal, use 0 if unknown. Output will be truncated to siglen samples.\n",
        "    :param frame_len: length of each frame measured in samples.\n",
        "    :param frame_step: number of samples after the start of the previous frame that the next frame should begin.\n",
        "    :param winfunc: the analysis window to apply to each frame. By default no window is applied.\n",
        "    :returns: a 1-D signal.\n",
        "    \"\"\"\n",
        "    frame_len = round_half_up(frame_len)\n",
        "    frame_step = round_half_up(frame_step)\n",
        "    numframes = numpy.shape(frames)[0]\n",
        "    assert numpy.shape(frames)[1] == frame_len, '\"frames\" matrix is wrong size, 2nd dim is not equal to frame_len'\n",
        "\n",
        "    indices = numpy.tile(numpy.arange(0, frame_len), (numframes, 1)) + numpy.tile(\n",
        "        numpy.arange(0, numframes * frame_step, frame_step), (frame_len, 1)).T\n",
        "    indices = numpy.array(indices, dtype=numpy.int32)\n",
        "    padlen = (numframes - 1) * frame_step + frame_len\n",
        "\n",
        "    if siglen <= 0: siglen = padlen\n",
        "\n",
        "    rec_signal = numpy.zeros((padlen,))\n",
        "    window_correction = numpy.zeros((padlen,))\n",
        "    win = winfunc(frame_len)\n",
        "\n",
        "    for i in range(0, numframes):\n",
        "        window_correction[indices[i, :]] = window_correction[\n",
        "                                               indices[i, :]] + win + 1e-15  # add a little bit so it is never zero\n",
        "        rec_signal[indices[i, :]] = rec_signal[indices[i, :]] + frames[i, :]\n",
        "\n",
        "    rec_signal = rec_signal / window_correction\n",
        "    return rec_signal[0:siglen]\n",
        "\n",
        "\n",
        "def magspec(frames, NFFT):\n",
        "    \"\"\"Compute the magnitude spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n",
        "\n",
        "    :param frames: the array of frames. Each row is a frame.\n",
        "    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n",
        "    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the magnitude spectrum of the corresponding frame.\n",
        "    \"\"\"\n",
        "    if numpy.shape(frames)[1] > NFFT:\n",
        "        logging.warn(\n",
        "            'frame length (%d) is greater than FFT size (%d), frame will be truncated. Increase NFFT to avoid.',\n",
        "            numpy.shape(frames)[1], NFFT)\n",
        "    complex_spec = numpy.fft.rfft(frames, NFFT)\n",
        "    return numpy.absolute(complex_spec)\n",
        "\n",
        "\n",
        "def powspec(frames, NFFT):\n",
        "    \"\"\"Compute the power spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n",
        "\n",
        "    :param frames: the array of frames. Each row is a frame.\n",
        "    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n",
        "    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the power spectrum of the corresponding frame.\n",
        "    \"\"\"\n",
        "    return 1.0 / NFFT * numpy.square(magspec(frames, NFFT))\n",
        "    #return 1.0 / NFFT * magspec(frames, NFFT)\n",
        "\n",
        "\n",
        "def logpowspec(frames, NFFT, norm=1):\n",
        "    \"\"\"Compute the log power spectrum of each frame in frames. If frames is an NxD matrix, output will be Nx(NFFT/2+1).\n",
        "\n",
        "    :param frames: the array of frames. Each row is a frame.\n",
        "    :param NFFT: the FFT length to use. If NFFT > frame_len, the frames are zero-padded.\n",
        "    :param norm: If norm=1, the log power spectrum is normalised so that the max value (across all frames) is 0.\n",
        "    :returns: If frames is an NxD matrix, output will be Nx(NFFT/2+1). Each row will be the log power spectrum of the corresponding frame.\n",
        "    \"\"\"\n",
        "    ps = powspec(frames, NFFT);\n",
        "    ps[ps <= 1e-30] = 1e-30\n",
        "    lps = 10 * numpy.log10(ps)\n",
        "    if norm:\n",
        "        return lps - numpy.max(lps)\n",
        "    else:\n",
        "        return lps\n",
        "\n",
        "\n",
        "def preemphasis(signal, coeff=0.95):\n",
        "    \"\"\"perform preemphasis on the input signal.\n",
        "\n",
        "    :param signal: The signal to filter.\n",
        "    :param coeff: The preemphasis coefficient. 0 is no filter, default is 0.95.\n",
        "    :returns: the filtered signal.\n",
        "    \"\"\"\n",
        "    return numpy.append(signal[0], signal[1:] - coeff * signal[:-1])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6T84jOlqNQfj"
      },
      "source": [
        "# calculate filterbank features. Provides e.g. fbank and mfcc features for use in ASR applications\n",
        "# Author: James Lyons 2012\n",
        "from __future__ import division\n",
        "import numpy\n",
        "from scipy.fftpack import dct\n",
        "\n",
        "def calculate_nfft(samplerate, winlen):\n",
        "    \"\"\"Calculates the FFT size as a power of two greater than or equal to\n",
        "    the number of samples in a single window length.\n",
        "    \n",
        "    Having an FFT less than the window length loses precision by dropping\n",
        "    many of the samples; a longer FFT than the window allows zero-padding\n",
        "    of the FFT buffer which is neutral in terms of frequency domain conversion.\n",
        "\n",
        "    :param samplerate: The sample rate of the signal we are working with, in Hz.\n",
        "    :param winlen: The length of the analysis window in seconds.\n",
        "    \"\"\"\n",
        "    window_length_samples = winlen * samplerate\n",
        "    nfft = 1\n",
        "    while nfft < window_length_samples:\n",
        "        nfft *= 2\n",
        "    return nfft\n",
        "\n",
        "def mfcc(signal,samplerate=16000,winlen=0.025,winstep=0.01,numcep=13,\n",
        "         nfilt=26,nfft=None,lowfreq=0,highfreq=None,preemph=0.97,ceplifter=22,appendEnergy=True,\n",
        "         winfunc=lambda x:numpy.ones((x,))):\n",
        "    \"\"\"Compute MFCC features from an audio signal.\n",
        "\n",
        "    :param signal: the audio signal from which to compute features. Should be an N*1 array\n",
        "    :param samplerate: the sample rate of the signal we are working with, in Hz.\n",
        "    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
        "    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
        "    :param numcep: the number of cepstrum to return, default 13\n",
        "    :param nfilt: the number of filters in the filterbank, default 26.\n",
        "    :param nfft: the FFT size. Default is None, which uses the calculate_nfft function to choose the smallest size that does not drop sample data.\n",
        "    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n",
        "    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n",
        "    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n",
        "    :param ceplifter: apply a lifter to final cepstral coefficients. 0 is no lifter. Default is 22.\n",
        "    :param appendEnergy: if this is true, the zeroth cepstral coefficient is replaced with the log of the total frame energy.\n",
        "    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n",
        "    :returns: A numpy array of size (NUMFRAMES by numcep) containing features. Each row holds 1 feature vector.\n",
        "    \"\"\"\n",
        "    nfft = nfft or calculate_nfft(samplerate, winlen)\n",
        "    feat,energy = fbank(signal,samplerate,winlen,winstep,nfilt,nfft,lowfreq,highfreq,preemph,winfunc)\n",
        "    feat = numpy.log(feat)\n",
        "    feat = dct(feat, type=2, axis=1, norm='ortho')[:,:numcep]\n",
        "    feat = lifter(feat,ceplifter)\n",
        "    if appendEnergy: feat[:,0] = numpy.log(energy) # replace first cepstral coefficient with log of frame energy\n",
        "    return feat\n",
        "\n",
        "def fbank(signal,samplerate=16000,winlen=0.025,winstep=0.01,\n",
        "          nfilt=26,nfft=512,lowfreq=0,highfreq=None,preemph=0.97,\n",
        "          winfunc=lambda x:numpy.ones((x,))):\n",
        "    \"\"\"Compute Mel-filterbank energy features from an audio signal.\n",
        "\n",
        "    :param signal: the audio signal from which to compute features. Should be an N*1 array\n",
        "    :param samplerate: the sample rate of the signal we are working with, in Hz.\n",
        "    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
        "    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
        "    :param nfilt: the number of filters in the filterbank, default 26.\n",
        "    :param nfft: the FFT size. Default is 512.\n",
        "    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n",
        "    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n",
        "    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n",
        "    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n",
        "    :returns: 2 values. The first is a numpy array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector. The\n",
        "        second return value is the energy in each frame (total energy, unwindowed)\n",
        "    \"\"\"\n",
        "    highfreq= highfreq or samplerate/2\n",
        "    signal = preemphasis(signal,preemph)\n",
        "    frames = framesig(signal, winlen*samplerate, winstep*samplerate, winfunc)\n",
        "    pspec = powspec(frames,nfft)\n",
        "    energy = numpy.sum(pspec,1) # this stores the total energy in each frame\n",
        "    energy = numpy.where(energy == 0,numpy.finfo(float).eps,energy) # if energy is zero, we get problems with log\n",
        "\n",
        "    fb = get_filterbanks(nfilt,nfft,samplerate,lowfreq,highfreq)\n",
        "    feat = numpy.dot(pspec,fb.T) # compute the filterbank energies\n",
        "    feat = numpy.where(feat == 0,numpy.finfo(float).eps,feat) # if feat is zero, we get problems with log\n",
        "    return feat,energy\n",
        "\n",
        "def logfbank(signal,samplerate=16000,winlen=0.025,winstep=0.01,\n",
        "             nfilt=26,nfft=512,lowfreq=0,highfreq=None,preemph=0.97,\n",
        "             winfunc=lambda x:numpy.ones((x,))):\n",
        "    \"\"\"Compute log Mel-filterbank energy features from an audio signal.\n",
        "\n",
        "    :param signal: the audio signal from which to compute features. Should be an N*1 array\n",
        "    :param samplerate: the sample rate of the signal we are working with, in Hz.\n",
        "    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
        "    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
        "    :param nfilt: the number of filters in the filterbank, default 26.\n",
        "    :param nfft: the FFT size. Default is 512.\n",
        "    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n",
        "    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n",
        "    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n",
        "    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n",
        "    :returns: A numpy array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector.\n",
        "    \"\"\"\n",
        "    feat,energy = fbank(signal,samplerate,winlen,winstep,nfilt,nfft,lowfreq,highfreq,preemph,winfunc)\n",
        "    return numpy.log(feat)\n",
        "\n",
        "def ssc(signal,samplerate=16000,winlen=0.025,winstep=0.01,\n",
        "        nfilt=26,nfft=512,lowfreq=0,highfreq=None,preemph=0.97,\n",
        "        winfunc=lambda x:numpy.ones((x,))):\n",
        "    \"\"\"Compute Spectral Subband Centroid features from an audio signal.\n",
        "\n",
        "    :param signal: the audio signal from which to compute features. Should be an N*1 array\n",
        "    :param samplerate: the sample rate of the signal we are working with, in Hz.\n",
        "    :param winlen: the length of the analysis window in seconds. Default is 0.025s (25 milliseconds)\n",
        "    :param winstep: the step between successive windows in seconds. Default is 0.01s (10 milliseconds)\n",
        "    :param nfilt: the number of filters in the filterbank, default 26.\n",
        "    :param nfft: the FFT size. Default is 512.\n",
        "    :param lowfreq: lowest band edge of mel filters. In Hz, default is 0.\n",
        "    :param highfreq: highest band edge of mel filters. In Hz, default is samplerate/2\n",
        "    :param preemph: apply preemphasis filter with preemph as coefficient. 0 is no filter. Default is 0.97.\n",
        "    :param winfunc: the analysis window to apply to each frame. By default no window is applied. You can use numpy window functions here e.g. winfunc=numpy.hamming\n",
        "    :returns: A numpy array of size (NUMFRAMES by nfilt) containing features. Each row holds 1 feature vector.\n",
        "    \"\"\"\n",
        "    highfreq= highfreq or samplerate/2\n",
        "    signal = preemphasis(signal,preemph)\n",
        "    frames = framesig(signal, winlen*samplerate, winstep*samplerate, winfunc)\n",
        "    pspec = powspec(frames,nfft)\n",
        "    pspec = numpy.where(pspec == 0,numpy.finfo(float).eps,pspec) # if things are all zeros we get problems\n",
        "\n",
        "    fb = get_filterbanks(nfilt,nfft,samplerate,lowfreq,highfreq)\n",
        "    feat = numpy.dot(pspec,fb.T) # compute the filterbank energies\n",
        "    R = numpy.tile(numpy.linspace(1,samplerate/2,numpy.size(pspec,1)),(numpy.size(pspec,0),1))\n",
        "\n",
        "    return numpy.dot(pspec*R,fb.T) / feat\n",
        "\n",
        "def hz2mel(hz):\n",
        "    \"\"\"Convert a value in Hertz to Mels\n",
        "\n",
        "    :param hz: a value in Hz. This can also be a numpy array, conversion proceeds element-wise.\n",
        "    :returns: a value in Mels. If an array was passed in, an identical sized array is returned.\n",
        "    \"\"\"\n",
        "    return 2595 * numpy.log10(1+hz/700.)\n",
        "\n",
        "def mel2hz(mel):\n",
        "    \"\"\"Convert a value in Mels to Hertz\n",
        "\n",
        "    :param mel: a value in Mels. This can also be a numpy array, conversion proceeds element-wise.\n",
        "    :returns: a value in Hertz. If an array was passed in, an identical sized array is returned.\n",
        "    \"\"\"\n",
        "    return 700*(10**(mel/2595.0)-1)\n",
        "\n",
        "def get_filterbanks(nfilt=20,nfft=512,samplerate=16000,lowfreq=0,highfreq=None):\n",
        "    \"\"\"Compute a Mel-filterbank. The filters are stored in the rows, the columns correspond\n",
        "    to fft bins. The filters are returned as an array of size nfilt * (nfft/2 + 1)\n",
        "\n",
        "    :param nfilt: the number of filters in the filterbank, default 20.\n",
        "    :param nfft: the FFT size. Default is 512.\n",
        "    :param samplerate: the sample rate of the signal we are working with, in Hz. Affects mel spacing.\n",
        "    :param lowfreq: lowest band edge of mel filters, default 0 Hz\n",
        "    :param highfreq: highest band edge of mel filters, default samplerate/2\n",
        "    :returns: A numpy array of size nfilt * (nfft/2 + 1) containing filterbank. Each row holds 1 filter.\n",
        "    \"\"\"\n",
        "    highfreq= highfreq or samplerate/2\n",
        "    assert highfreq <= samplerate/2, \"highfreq is greater than samplerate/2\"\n",
        "\n",
        "    # compute points evenly spaced in mels\n",
        "    lowmel = hz2mel(lowfreq)\n",
        "    highmel = hz2mel(highfreq)\n",
        "    melpoints = numpy.linspace(lowmel,highmel,nfilt+2)\n",
        "    # our points are in Hz, but we use fft bins, so we have to convert\n",
        "    #  from Hz to fft bin number\n",
        "    bin = numpy.floor((nfft+1)*mel2hz(melpoints)/samplerate)\n",
        "\n",
        "    fbank = numpy.zeros([nfilt,nfft//2+1])\n",
        "    for j in range(0,nfilt):\n",
        "        for i in range(int(bin[j]), int(bin[j+1])):\n",
        "            fbank[j,i] = (i - bin[j]) / (bin[j+1]-bin[j])\n",
        "        for i in range(int(bin[j+1]), int(bin[j+2])):\n",
        "            fbank[j,i] = (bin[j+2]-i) / (bin[j+2]-bin[j+1])\n",
        "    return fbank\n",
        "\n",
        "def lifter(cepstra, L=22):\n",
        "    \"\"\"Apply a cepstral lifter the the matrix of cepstra. This has the effect of increasing the\n",
        "    magnitude of the high frequency DCT coeffs.\n",
        "\n",
        "    :param cepstra: the matrix of mel-cepstra, will be numframes * numcep in size.\n",
        "    :param L: the liftering coefficient to use. Default is 22. L <= 0 disables lifter.\n",
        "    \"\"\"\n",
        "    if L > 0:\n",
        "        nframes,ncoeff = numpy.shape(cepstra)\n",
        "        n = numpy.arange(ncoeff)\n",
        "        lift = 1 + (L/2.)*numpy.sin(numpy.pi*n/L)\n",
        "        return lift*cepstra\n",
        "    else:\n",
        "        # values of L <= 0, do nothing\n",
        "        return cepstra\n",
        "\n",
        "def delta(feat, N):\n",
        "    \"\"\"Compute delta features from a feature vector sequence.\n",
        "\n",
        "    :param feat: A numpy array of size (NUMFRAMES by number of features) containing features. Each row holds 1 feature vector.\n",
        "    :param N: For each frame, calculate delta features based on preceding and following N frames\n",
        "    :returns: A numpy array of size (NUMFRAMES by number of features) containing delta features. Each row holds 1 delta feature vector.\n",
        "    \"\"\"\n",
        "    if N < 1:\n",
        "        raise ValueError('N must be an integer >= 1')\n",
        "    NUMFRAMES = len(feat)\n",
        "    denominator = 2 * sum([i**2 for i in range(1, N+1)])\n",
        "    delta_feat = numpy.empty_like(feat)\n",
        "    padded = numpy.pad(feat, ((N, N), (0, 0)), mode='edge')   # padded version of feat\n",
        "    for t in range(NUMFRAMES):\n",
        "        delta_feat[t] = numpy.dot(numpy.arange(-N, N+1), padded[t : t+2*N+1]) / denominator   # [t : t+2*N+1] == [(N+t)-N : (N+t)+N+1]\n",
        "    return delta_feat\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BpzuP1_jNSjj"
      },
      "source": [
        "def get_band_filter_coeff(samplerate, f0, Q=1.0):\n",
        "    \"\"\"\n",
        "    Bandpass filter based on BLT: Cookbook formulae for audio EQ biquad filter coefficients\n",
        "    https://gist.github.com/RyanMarcus/d3386baa6b4cb1ac47f4#file-gistfile1-txt\n",
        "    \"\"\"\n",
        "    w0 = 2 * np.pi * f0 / samplerate\n",
        "    alpha = np.sin(w0) / (2 * Q)\n",
        "    a = np.zeros(3)\n",
        "    b = np.zeros(3)\n",
        "    b[0] = Q*alpha\n",
        "    b[1] = 0\n",
        "    b[2] = -Q*alpha\n",
        "    a[0] = 1 + alpha\n",
        "    a[1] = -2*np.cos(w0)\n",
        "    a[2] = 1-alpha\n",
        "    return  b, a\n",
        "\n",
        "def iir_design_first_order(band_frequency, samplerate, normalize=True): # the ban frequency is the middel fre\n",
        "    b = []\n",
        "    a = []\n",
        "    for i in range(len(band_frequency)):\n",
        "        b_, a_ = get_band_filter_coeff(samplerate, band_frequency[i])\n",
        "        if(normalize):\n",
        "            b_ = b_/a_[0]           # unified\n",
        "            a_[1:] = a_[1:]/a_[0]\n",
        "            a_[0] = 1\n",
        "        b.append(b_)\n",
        "        a.append(a_)\n",
        "    return b, a\n",
        "    # Ref implementation:\n",
        "    # b, a = set_gains(b_in, a_in, alpha, gains[0])\n",
        "    # i = 0\n",
        "    # g = 0\n",
        "    # for n in range(2, len(x)):\n",
        "    #     y[n] = b[0] * x[n] + b[1] * x[n - 1] + b[2] * x[n - 2] - a[1]* y[n - 1] - a[2] * y[n - 2]\n",
        "    #     if (n % step == 0 and i < len(gains)-1):\n",
        "    #         i += 1\n",
        "    #         g = gains[i] * 0.4 + g*0.6\n",
        "    #         b, a = set_gains(b_in, a_in, alpha, g)\n",
        "    # return y\n",
        "\n",
        "def generate_filter_header(b, a, order, filename='equalizer_coeff.h'):\n",
        "    def array2str(data):\n",
        "        s = np.array2string(np.array(data).flatten(), separator=',')\n",
        "        return s.replace(\"\\n\", \"\").replace(\"\\r\", \"\").replace(' ', '').replace(',', ', ').replace('[', '{').replace(']', '}')\n",
        "    with open(filename, 'w') as file:\n",
        "        file.write(\"\\n#define NUM_FILTER \" + str(len(b)) + '\\n')\n",
        "        file.write(\"\\n#define NUM_ORDER \" +  str(order) + '\\n')\n",
        "        file.write(\"\\n#define NUM_COEFF_PAIR \" + str(order*2+1) + '\\n')\n",
        "        file.write(\"\\n#define FILTER_COEFF_A \" + array2str(a) + \"\\n\")\n",
        "        file.write(\"\\n#define FILTER_COEFF_B \" + array2str(b) + \"\\n\")\n",
        "\n",
        "def iir_design(band_frequency, samplerate, order=1): # the ban frequency is the middel fre\n",
        "    b = []\n",
        "    a = []\n",
        "    fre = band_frequency / (samplerate/2)\n",
        "    for i in range(1, len(band_frequency)-1):\n",
        "        b_, a_ = signal.iirfilter(order, [fre[i] - (fre[i]-fre[i-1])/2, fre[i]+ (fre[i+1]-fre[i])/2],\n",
        "                                  btype='bandpass', output='ba')\n",
        "        # b_, a_ = signal.iirfilter(order, [fre[i-1], fre[i+1]-0.001],\n",
        "        #                            btype='bandpass', output='ba')\n",
        "        # b_, a_ = signal.cheby1(order, 1, [fre[i] - (fre[i]-fre[i-1])/2, fre[i]+ (fre[i+1]-fre[i])/2],\n",
        "        #                           btype='bandpass', output='ba')\n",
        "        b.append(b_)\n",
        "        a.append(a_)\n",
        "    return b, a\n",
        "\n",
        "def fir_design(band_frequency, samplerate, order=51):\n",
        "    from scipy import signal\n",
        "    b = []\n",
        "    fre = band_frequency / (samplerate/2)\n",
        "    for i in range(1, len(band_frequency)-1):\n",
        "        b.append(signal.firwin(order, [fre[i] - (fre[i]-fre[i-1])/2, fre[i]+ (fre[i+1]-fre[i])/2], pass_zero='bandpass'))\n",
        "    return b\n",
        "\n",
        "def get_mel_scale(nfilt=20, samplerate=16000, lowfreq=20, highfreq=8000):\n",
        "    highfreq = highfreq or samplerate / 2\n",
        "    assert highfreq <= samplerate / 2, \"highfreq is greater than samplerate/2\"\n",
        "    # compute points evenly spaced in mels\n",
        "    lowmel = hz2mel(lowfreq)\n",
        "    highmel = hz2mel(highfreq)\n",
        "    melpoints = np.linspace(lowmel, highmel, nfilt + 2)\n",
        "    return melpoints\n",
        "\n",
        "def bandpass_filter_fir(sig, b_in, a_in, step, gains):\n",
        "    from scipy import signal\n",
        "    x = sig\n",
        "    y = np.zeros(len(x))\n",
        "    state = np.zeros(len(b_in)-1)\n",
        "    g=0\n",
        "    for n in range(0, len(gains)):\n",
        "        g = max(0.8*g, gains[n])    # pre RNNoise paper https://arxiv.org/pdf/1709.08243.pdf\n",
        "        b = b_in * g\n",
        "        filtered, state = signal.lfilter(b, 1, x[n*step: min((n+1)*step, len(x))], zi=state)\n",
        "        y[n*step: min((n+1)*step, len(x))] = filtered\n",
        "    return y\n",
        "\n",
        "def bandpass_filter_iir(sig, b_in, a_in, step, gains):\n",
        "    from scipy import signal\n",
        "    x = sig\n",
        "    y = np.zeros(len(x))\n",
        "    state = np.zeros(len(b_in)-1)\n",
        "    g=0\n",
        "    for n in range(0, len(gains)):\n",
        "        g = max(0.6*g, gains[n])    # r=0.6 pre RNNoise paper https://arxiv.org/pdf/1709.08243.pdf\n",
        "        b = b_in*g\n",
        "        a = a_in\n",
        "        filtered, state = signal.lfilter(b, a, x[n*step: min((n+1)*step, len(x))], zi=state)\n",
        "        y[n*step: min((n+1)*step, len(x))] = filtered\n",
        "    return y\n",
        "\n",
        "\n",
        "def plot_frequency_respond(b, a=None, fs=16000):\n",
        "    a = a if len(a) == len(b)  else np.ones(len(b))\n",
        "    for i in range(len(b)):\n",
        "        w, h = signal.freqz(b[i], a[i])\n",
        "        plt.plot(w*0.15915494327*fs, 20 * np.log10(np.maximum(abs(h), 1e-5)), 'b')\n",
        "    plt.title('Digital filter frequency response')\n",
        "    plt.ylabel('Amplitude [dB]', color='b')\n",
        "    plt.xlabel('Frequency [Hz]')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpjPOKL1NWEi",
        "outputId": "a8dedf2d-60f3-473d-d75d-88c12156ee10"
      },
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras import *\n",
        "from tensorflow.keras  import backend as K\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import load_model, save_model\n",
        "from scipy import signal\n",
        "import scipy.io.wavfile as wav\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "\n",
        "def my_crossentropy(y_true, y_pred):\n",
        "    return K.mean(2*K.abs(y_true-0.5) * K.binary_crossentropy(y_pred, y_true), axis=-1)\n",
        "\n",
        "def mymask(y_true):\n",
        "    return K.minimum(y_true+1., 1.)\n",
        "\n",
        "def msse(y_true, y_pred):\n",
        "    return K.mean(mymask(y_true) * K.square(K.sqrt(y_pred) - K.sqrt(y_true)), axis=-1)\n",
        "\n",
        "def mycost(y_true, y_pred):\n",
        "     return K.mean(mymask(y_true) * (10*K.square(K.square(K.sqrt(y_pred) - K.sqrt(y_true))) + K.square(K.sqrt(y_pred) - K.sqrt(y_true)) + 0.01*K.binary_crossentropy(y_pred, y_true)), axis=-1)\n",
        "\n",
        "def my_accuracy(y_true, y_pred):\n",
        "    return K.mean(2*K.abs(y_true-0.5) * K.equal(y_true, K.round(y_pred)), axis=-1)\n",
        "\n",
        "\n",
        "def filter_voice(sig, rate, gains, nband=26, lowfreq=20, highfreq=8000):\n",
        "    # see gen_dataset.py's example for detial\n",
        "    mel_scale = get_mel_scale(nfilt=nband, lowfreq=lowfreq, highfreq=highfreq)\n",
        "    band_freq = mel2hz(mel_scale)\n",
        "    band_frequency = band_freq[1:-1] # the middle point of each band\n",
        "    print('band frequency', band_frequency)\n",
        "    b, a = iir_design(band_freq, rate)\n",
        "    step = int(0.032 * rate * 0.2)\n",
        "    filtered_signal = np.zeros(len(sig))\n",
        "    for i in range(len(b)):\n",
        "        filtered_signal += bandpass_filter_iir(sig, b[i].copy(), a[i].copy(), step, gains[:, i])\n",
        "        print(\"filtering with frequency: \", band_frequency[i])\n",
        "    filtered_signal =filtered_signal * 0.6\n",
        "    return filtered_signal\n",
        "\n",
        "def normalize(data, n, quantize=True):\n",
        "    limit = pow(2, n)\n",
        "    data = np.clip(data, -limit, limit)/limit\n",
        "    if quantize:\n",
        "        data = np.round(data * 128)/ 128.0\n",
        "    return data\n",
        "\n",
        "def voice_denoise(sig, rate, model, timestamp_size, numcep=26, plot=False):\n",
        "    sig = sig / 32768\n",
        "    # get the mfcc of noisy voice\n",
        "    mfcc_feat = mfcc(sig, rate, winlen=0.032, winstep=0.032*0.2, numcep=numcep, nfilt=numcep, nfft=512,\n",
        "                     lowfreq=20, highfreq=8000, winfunc=np.hanning, ceplifter=0, preemph=0, appendEnergy=True)\n",
        "    mfcc_feat = mfcc_feat.astype('float32')\n",
        "\n",
        "    # differential of mfcc, add 0 to the beginning\n",
        "    diff = np.diff(mfcc_feat, axis=0)\n",
        "    diff = np.concatenate([[mfcc_feat[0]], diff], axis=0)  # first derivative\n",
        "    diff1 = np.diff(diff, axis=0)\n",
        "    diff1 = np.concatenate([[diff[0]], diff1], axis=0) # second derivative\n",
        "    diff = diff[:, :10]\n",
        "    diff1 = diff1[:, :10]\n",
        "\n",
        "    # concat both differential and original mfcc\n",
        "    feat = np.concatenate([mfcc_feat, diff, diff1], axis=-1)\n",
        "\n",
        "    # requantise the MFCC (same as training data)\n",
        "    feat = normalize(feat, 3, quantize=False)\n",
        "    # plt.hist(feat.flatten(), bins=1000)\n",
        "    # plt.show()\n",
        "\n",
        "    # interference.\n",
        "    feat = np.reshape(feat, (feat.shape[0], 1, feat.shape[1]))\n",
        "    feat = feat[: feat.shape[0] // timestamp_size * timestamp_size]\n",
        "    prediction = model.predict(feat, batch_size=timestamp_size)\n",
        "    if(type(prediction) is list):\n",
        "        predicted_gains = prediction[0]\n",
        "        predicted_vad = prediction[1]\n",
        "    else:\n",
        "        predicted_gains = prediction\n",
        "        predicted_vad = None\n",
        "\n",
        "    # now process the signal.\n",
        "    filtered_sig = filter_voice(sig, rate=rate, gains=predicted_gains, nband=mfcc_feat.shape[-1])\n",
        "    if(plot):\n",
        "        for i in range(10):\n",
        "            plt.plot(predicted_gains[:, i], label='band'+str(i))\n",
        "        if(predicted_vad is not None):\n",
        "            plt.plot(predicted_vad, 'r', label='VAD')\n",
        "        plt.ylabel(\"Gains\")\n",
        "        plt.xlabel(\"MFCC Sample\")\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "    return filtered_sig\n",
        "\n",
        "# differential of mfcc, add 0 to the beginning\n",
        "def get_diff_list(data):\n",
        "    L = []\n",
        "    for d in data:\n",
        "        L.append(np.concatenate([[d[0]], np.diff(d, axis=-2)], axis=-2))\n",
        "    return np.array(L)\n",
        "\n",
        "# we need to reset state in RNN. becasue we dont each batch are different. however, we need statful=true for nnom\n",
        "class reset_state_after_batch(tf.keras.callbacks.Callback):\n",
        "    reset_after = 1 # reset state after N batch.\n",
        "    curr = 0\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        self.curr += 1\n",
        "        if(self.curr >= self.reset_after):\n",
        "            self.curr = 0\n",
        "            self.model.reset_states()\n",
        "        pass\n",
        "\n",
        "\n",
        "def train(x_train, y_train, vad_train, batch_size=64, epochs=10, model_name=\"proposed_model_all.h5\"):\n",
        "    \"\"\"\n",
        "    RNNoise-like structure with some adaption to fit NNoM's implementation.\n",
        "    \"\"\"\n",
        "    input_feature_size = x_train.shape[-1]\n",
        "    output_feature_size = y_train.shape[-1]\n",
        "    timestamp_size = batch_size\n",
        "    input = Input(shape=(1, input_feature_size), batch_size=timestamp_size)\n",
        "\n",
        "    \"\"\"\n",
        "        This is an RNNoise-like structure\n",
        "    \"\"\"\n",
        "\n",
        "    # voice activity detection\n",
        "    x1_1 = tf.keras.layers.Dense(24, activation=\"tanh\")(input)\n",
        "    x1_2 = tf.keras.layers.GRU(24, activation=\"relu\", reset_after=False, return_sequences=True, recurrent_dropout=0.4)(x1_1)\n",
        "    # x1_2 = tf.keras.layers.GRU(24, activation=\"relu\", reset_after=False, return_sequences=True)(x1_1)\n",
        "    x1_2 = tf.keras.layers.Dropout(0.5)(x1_2)\n",
        "    x = tf.keras.layers.concatenate([x1_2, input], axis=-1) # skip connection VAD\n",
        "    # x = tf.keras.layers.Flatten()(x1_2)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    vad_output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    # Noise spectral estimation\n",
        "    x2 = tf.keras.layers.concatenate([input, x1_1, x1_2], axis=-1)\n",
        "    x2 = tf.keras.layers.GRU(48, activation=\"relu\", reset_after=False, return_sequences=True, recurrent_dropout=0.4)(x2)\n",
        "    # x2 = tf.keras.layers.GRU(48, activation=\"relu\", reset_after=False, return_sequences=True)(x2)\n",
        "    x2 = tf.keras.layers.Dropout(0.5)(x2)\n",
        "\n",
        "    #Spectral subtraction\n",
        "    x3 = tf.keras.layers.concatenate([input, x2, x1_2], axis=-1)\n",
        "    x3 = tf.keras.layers.GRU(96, activation=\"relu\", reset_after=False, return_sequences=True, recurrent_dropout=0.4)(x3)\n",
        "    # x3 = tf.keras.layers.GRU(96, activation=\"relu\", reset_after=False, return_sequences=True)(x3)\n",
        "    x3 = tf.keras.layers.Dropout(0.5)(x3)\n",
        "    x = tf.keras.layers.concatenate([x3, input], axis=-1) # skip connection Gains\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    # x = tf.keras.layers.Flatten()(x3)\n",
        "    x = tf.keras.layers.Dense(output_feature_size, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs=input, outputs=[x, vad_output])\n",
        "    # model.compile(\"adam\", loss=[mycost, my_crossentropy], loss_weights=[10, 0.5], metrics=[msse])\n",
        "    # model.compile(\"adam\", loss=[mycost, my_crossentropy], loss_weights=[10, 2], metrics=[msse]) # RNNoise loss and cost\n",
        "    # model.compile(\"adam\", loss=[\"MSE\", my_crossentropy], loss_weights=[10, 0.5], metrics=[msse])\n",
        "    model.compile(\"adam\", loss=[\"MSE\", my_crossentropy], loss_weights=[10, 3], metrics=[msse])   \n",
        "    model.summary()\n",
        "\n",
        "    history = model.fit(x_train, [y_train, vad_train], batch_size=timestamp_size, epochs=epochs, verbose=2, shuffle=False)\n",
        "\n",
        "    # free the session to avoid nesting naming while we load the best model after.\n",
        "    save_model(model, model_name)\n",
        "    del model\n",
        "    tf.keras.backend.clear_session()\n",
        "    return history\n",
        "\n",
        "\n",
        "def main():\n",
        "    # # load test dataset. Generate by gen_dataset.py see the file for details.\n",
        "    try:\n",
        "        dataset = np.load('drive/MyDrive/Noise suppression/dataset_all.npz', allow_pickle=True)\n",
        "    except:\n",
        "        raise Exception(\"dataset_all.npz not found, please run 'gen_dataset.py' to create dataset\")\n",
        "\n",
        "    # combine them together\n",
        "    clnsp_mfcc = dataset['clnsp_mfcc']    # mfcc\n",
        "    noisy_mfcc = dataset['noisy_mfcc']\n",
        "    vad = dataset['vad']                  # voice active detection\n",
        "    gains = dataset['gains']              # gains\n",
        "\n",
        "    # get mfcc derivative from dataset.\n",
        "    clnsp_mfcc_diff = get_diff_list(clnsp_mfcc)\n",
        "    noisy_mfcc_diff = get_diff_list(noisy_mfcc)\n",
        "    clnsp_mfcc_diff1 = get_diff_list(clnsp_mfcc_diff)\n",
        "    noisy_mfcc_diff1 = get_diff_list(noisy_mfcc_diff)\n",
        "\n",
        "    # combine all pices to one large array\n",
        "    clnsp_mfcc = np.concatenate(clnsp_mfcc, axis=0)\n",
        "    noisy_mfcc = np.concatenate(noisy_mfcc, axis=0)\n",
        "    clnsp_mfcc_diff = np.concatenate(clnsp_mfcc_diff, axis=0)\n",
        "    noisy_mfcc_diff = np.concatenate(noisy_mfcc_diff, axis=0)\n",
        "    clnsp_mfcc_diff1 = np.concatenate(clnsp_mfcc_diff1, axis=0)\n",
        "    noisy_mfcc_diff1 = np.concatenate(noisy_mfcc_diff1, axis=0)\n",
        "    vad = np.concatenate(vad, axis=0)\n",
        "    gains = np.concatenate(gains, axis=0)\n",
        "\n",
        "    # these max and min are rear\n",
        "    print('mfcc max:', noisy_mfcc.max(), 'mfcc min:', noisy_mfcc.min())\n",
        "    print('mfcc diff max:', noisy_mfcc_diff.max(), 'mfcc diff min:', noisy_mfcc_diff.min())\n",
        "\n",
        "    # preprocess data\n",
        "    timestamp_size = 2048 # this must be > than 1024, since we are using 1 one sample as a batch, which still too small for BP\n",
        "    num_sequence = len(vad) // timestamp_size\n",
        "    print('timestamp', timestamp_size, 'num of data', num_sequence)\n",
        "\n",
        "    # prepare data\n",
        "    diff = np.copy(noisy_mfcc_diff[:num_sequence * timestamp_size, :10])\n",
        "    diff1 = np.copy(noisy_mfcc_diff1[:num_sequence * timestamp_size, :10])\n",
        "    feat = np.copy(noisy_mfcc[:num_sequence * timestamp_size, :])\n",
        "\n",
        "    # concat mfcc, 1st and 2nd derivative together as the training data.\n",
        "    x_train = np.concatenate([feat, diff, diff1], axis=-1)\n",
        "    # convert MFCC range to -1 to 1.0 In quantization, we will saturate them to leave more resolution in smaller numbers\n",
        "    # we saturate the peak to leave some more resolution in other band.\n",
        "    x_train = normalize(x_train, 3, quantize=False)\n",
        "    # plt.hist(gains.flatten(), bins=1000)\n",
        "    # plt.show()\n",
        "\n",
        "    # reshape\n",
        "    x_train = np.copy(x_train[:num_sequence * timestamp_size, :])\n",
        "    x_train = np.reshape(x_train, (num_sequence* timestamp_size, 1, x_train.shape[-1]))\n",
        "    y_train = np.copy(gains[:num_sequence * timestamp_size,:])\n",
        "    y_train = np.reshape(y_train, (num_sequence* timestamp_size, gains.shape[-1]))\n",
        "    vad_train = np.copy(vad[:num_sequence * timestamp_size]).astype(np.float32)\n",
        "    vad_train = np.reshape(vad_train, (num_sequence * timestamp_size, 1))\n",
        "\n",
        "    # train the model, choose either one.\n",
        "    history = train(x_train, y_train, vad_train, batch_size=timestamp_size, epochs=10, model_name=\"proposed_model_all.h5\")\n",
        "    # history = train_simple(x_train, y_train, vad_train, batch_size=timestamp_size, epochs=10, model_name=\"proposed_model_all.h5\")\n",
        "\n",
        "    # get the model\n",
        "    model = load_model(\"drive/MyDrive/Noise suppression/proposed_model_all.h5\", custom_objects={'mycost': mycost, 'msse':msse, 'my_crossentropy':my_crossentropy, 'my_accuracy':my_accuracy})\n",
        "\n",
        "    # denoise a file for test.\n",
        "    # Make sure the MFCC parameters inside the voice_denoise() are snithe same as our gen_dataset.\n",
        "    (rate, sig) = wav.read(\"drive/MyDrive/Noise suppression/_noisy_sample_typing.wav\")\n",
        "    filtered_sig = voice_denoise(sig, rate, model, timestamp_size, numcep=y_train.shape[-1], plot=True) # use plot=True argument to see the gains/vad\n",
        "    wav.write(\"drive/MyDrive/Noise suppression/_pm-toa_denoised_noisySampleTyping.wav\", rate, np.asarray(filtered_sig * 32767, dtype=np.int16))\n",
        "\n",
        "    # plot loss\n",
        "    # plt.figure(figsize=(20, 7))\n",
        "    # plt.plot(history.history['loss'], label='training loss')\n",
        "    # plt.ylabel(\"Loss\")\n",
        "    # plt.xlabel(\"Time\")\n",
        "    # plt.legend()\n",
        "    # plt.show()\n",
        "    return\n",
        "\n",
        "# Press the green button in the gutter to run the script.\n",
        "if __name__ == '__main__':\n",
        "    \n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:106: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "mfcc max: 27.73978 mfcc min: -40.40547\n",
            "mfcc diff max: 34.356 mfcc diff min: -35.09329\n",
            "timestamp 2048 num of data 2812\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(2048, 1, 42)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (2048, 1, 24)        1032        input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru (GRU)                       (2048, 1, 24)        3528        dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (2048, 1, 24)        0           gru[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (2048, 1, 90)        0           input_1[0][0]                    \n",
            "                                                                 dense[0][0]                      \n",
            "                                                                 dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru_1 (GRU)                     (2048, 1, 48)        20016       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (2048, 1, 48)        0           gru_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (2048, 1, 114)       0           input_1[0][0]                    \n",
            "                                                                 dropout_1[0][0]                  \n",
            "                                                                 dropout[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru_2 (GRU)                     (2048, 1, 96)        60768       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (2048, 1, 96)        0           gru_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (2048, 1, 138)       0           dropout_2[0][0]                  \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (2048, 1, 66)        0           dropout[0][0]                    \n",
            "                                                                 input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (2048, 138)          0           concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (2048, 66)           0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (2048, 22)           3058        flatten_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (2048, 1)            67          flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 88,469\n",
            "Trainable params: 88,469\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "2812/2812 - 150s - loss: 10.6545 - dense_2_loss: 0.1144 - dense_1_loss: 3.1701 - dense_2_msse: 0.1318 - dense_1_msse: 0.1633\n",
            "Epoch 2/10\n",
            "2812/2812 - 146s - loss: 8.6946 - dense_2_loss: 0.0981 - dense_1_loss: 2.5710 - dense_2_msse: 0.1127 - dense_1_msse: 0.1482\n",
            "Epoch 3/10\n",
            "2812/2812 - 144s - loss: 8.2815 - dense_2_loss: 0.0928 - dense_1_loss: 2.4512 - dense_2_msse: 0.1063 - dense_1_msse: 0.1446\n",
            "Epoch 4/10\n",
            "2812/2812 - 144s - loss: 8.0091 - dense_2_loss: 0.0894 - dense_1_loss: 2.3718 - dense_2_msse: 0.1020 - dense_1_msse: 0.1411\n",
            "Epoch 5/10\n",
            "2812/2812 - 144s - loss: 7.8414 - dense_2_loss: 0.0868 - dense_1_loss: 2.3245 - dense_2_msse: 0.0987 - dense_1_msse: 0.1391\n",
            "Epoch 6/10\n",
            "2812/2812 - 144s - loss: 7.7136 - dense_2_loss: 0.0847 - dense_1_loss: 2.2888 - dense_2_msse: 0.0962 - dense_1_msse: 0.1376\n",
            "Epoch 7/10\n",
            "2812/2812 - 144s - loss: 7.6092 - dense_2_loss: 0.0831 - dense_1_loss: 2.2594 - dense_2_msse: 0.0944 - dense_1_msse: 0.1363\n",
            "Epoch 8/10\n",
            "2812/2812 - 143s - loss: 7.5306 - dense_2_loss: 0.0821 - dense_1_loss: 2.2366 - dense_2_msse: 0.0932 - dense_1_msse: 0.1356\n",
            "Epoch 9/10\n",
            "2812/2812 - 142s - loss: 7.4796 - dense_2_loss: 0.0812 - dense_1_loss: 2.2224 - dense_2_msse: 0.0922 - dense_1_msse: 0.1353\n",
            "Epoch 10/10\n",
            "2812/2812 - 142s - loss: 7.4287 - dense_2_loss: 0.0804 - dense_1_loss: 2.2082 - dense_2_msse: 0.0913 - dense_1_msse: 0.1348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-317a56b2ee09>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-1-317a56b2ee09>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0;31m# Make sure the MFCC parameters inside the voice_denoise() are the same as our gen_dataset.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/MyDrive/Noise suppression/_noisy_sample_typing.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0mfiltered_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoice_denoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumcep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# use plot=True argument to see the gains/vad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m     \u001b[0mwav\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/MyDrive/Noise suppression/_pm-toa_denoised_noisySampleTyping.wav\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_sig\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32767\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-317a56b2ee09>\u001b[0m in \u001b[0;36mvoice_denoise\u001b[0;34m(sig, rate, model, timestamp_size, numcep, plot)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msig\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m32768\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# get the mfcc of noisy voice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     mfcc_feat = mfcc(sig, rate, winlen=0.032, winstep=0.032*0.2, numcep=numcep, nfilt=numcep, nfft=512,\n\u001b[0m\u001b[1;32m     58\u001b[0m                      lowfreq=20, highfreq=8000, winfunc=np.hanning, ceplifter=0, preemph=0, appendEnergy=True)\n\u001b[1;32m     59\u001b[0m     \u001b[0mmfcc_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmfcc_feat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mfcc' is not defined"
          ]
        }
      ]
    }
  ]
}