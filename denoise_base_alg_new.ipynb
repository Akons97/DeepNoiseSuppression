{
 "cells": [
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "Could not find module 'C:\\Users\\Adam\\anaconda3\\envs\\deepns_env\\lib\\site-packages\\scipy\\.libs\\libbanded5x.3OIBJ6VWWPY6GDLEMSTXSIPCHHWASXGT.gfortran-win_amd64.dll' (or one of its dependencies). Try using the full path with constructor syntax.",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-20df4158ff8d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msoundfile\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msignal\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deepns_env\\lib\\site-packages\\librosa\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;31m# And all the librosa sub-modules\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mbeat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdecompose\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deepns_env\\lib\\site-packages\\librosa\\core\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;34m\"\"\" Core IO and DSP functions\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mconvert\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# pylint: disable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0maudio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# pylint: disable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mspectrum\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# pylint: disable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deepns_env\\lib\\site-packages\\librosa\\core\\convert.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnotation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParameterError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deepns_env\\lib\\site-packages\\librosa\\core\\notation.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mParameterError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m __all__ = [\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deepns_env\\lib\\site-packages\\librosa\\util\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     81\u001b[0m \"\"\"\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# pylint: disable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mfiles\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# pylint: disable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmatching\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m  \u001b[1;31m# pylint: disable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deepns_env\\lib\\site-packages\\librosa\\util\\utils.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deepns_env\\lib\\site-packages\\scipy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;31m# Allow distributors to run custom init code\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_pep440\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deepns_env\\lib\\site-packages\\scipy\\_distributor_init.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibs_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibs_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'*dll'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m                 \u001b[0mWinDLL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mowd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\deepns_env\\lib\\ctypes\\__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 373\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    374\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    375\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Could not find module 'C:\\Users\\Adam\\anaconda3\\envs\\deepns_env\\lib\\site-packages\\scipy\\.libs\\libbanded5x.3OIBJ6VWWPY6GDLEMSTXSIPCHHWASXGT.gfortran-win_amd64.dll' (or one of its dependencies). Try using the full path with constructor syntax."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa as lr\n",
    "import soundfile as sf\n",
    "from scipy import signal\n",
    "# import pysepm\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras  import backend as K\n",
    "from tensorflow.keras.models import load_model, save_model\n",
    "\n"
   ]
  },
  {
   "source": [
    "## Utility functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_crossentropy(y_true, y_pred):\n",
    "    return K.mean(2*K.abs(y_true-0.5) * K.binary_crossentropy(y_pred, y_true), axis=-1)\n",
    "\n",
    "def mymask(y_true):\n",
    "    return K.minimum(y_true+1., 1.)\n",
    "\n",
    "def msse(y_true, y_pred):\n",
    "    return K.mean(mymask(y_true) * K.square(K.sqrt(y_pred) - K.sqrt(y_true)), axis=-1)\n",
    "\n",
    "def mycost(y_true, y_pred):\n",
    "     return K.mean(mymask(y_true) * (10*K.square(K.square(K.sqrt(y_pred) - K.sqrt(y_true))) + K.square(K.sqrt(y_pred) - K.sqrt(y_true)) + 0.01*K.binary_crossentropy(y_pred, y_true)), axis=-1)\n",
    "\n",
    "def my_accuracy(y_true, y_pred):\n",
    "    return K.mean(2*K.abs(y_true-0.5) * K.equal(y_true, K.round(y_pred)), axis=-1)\n",
    "\n",
    "\n",
    "# list of mfcc differentials, adds 0 to the beginning\n",
    "def get_diff_list(data):\n",
    "    L = []\n",
    "    for d in data:\n",
    "        L.append(np.concatenate([[d[0]], np.diff(d, axis=-2)], axis=-2))\n",
    "    return np.array(L)\n",
    "\n",
    "\n",
    "def normalize(data, n, quantize=True):\n",
    "    limit = pow(2, n)\n",
    "    data = np.clip(data, -limit, limit)/limit\n",
    "    if quantize:\n",
    "        data = np.round(data * 128)/ 128.0\n",
    "    return data\n",
    "\n",
    "\n",
    "def iir_design(band_frequency, samplerate, order=1): # the band frequency is the middle freq\n",
    "    b = []\n",
    "    a = []\n",
    "    fre = band_frequency / (samplerate/2)\n",
    "    for i in range(1, len(band_frequency)-1):\n",
    "        b_, a_ = signal.iirfilter(order, [fre[i] - (fre[i]-fre[i-1])/2, fre[i]+ (fre[i+1]-fre[i])/2], btype='bandpass', output='ba')\n",
    "        b.append(b_)\n",
    "        a.append(a_)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def bandpass_filter_iir(sig, b_in, a_in, step, gains):\n",
    "    x = sig\n",
    "    y = np.zeros(len(x))\n",
    "    state = np.zeros(len(b_in)-1)\n",
    "    g=0\n",
    "    for n in range(0, len(gains)):\n",
    "        g = max(0.6*g, gains[n])    # r=0.6 pre RNNoise paper https://arxiv.org/pdf/1709.08243.pdf\n",
    "        b = b_in*g\n",
    "        a = a_in\n",
    "        filtered, state = signal.lfilter(b, a, x[n*step: min((n+1)*step, len(x))], zi=state)\n",
    "        y[n*step: min((n+1)*step, len(x))] = filtered\n",
    "    return y\n",
    "\n",
    "\n",
    "def filter_voice(sig, rate, gains, nband=22, lowfreq=20, highfreq=4000):\n",
    "    # see gen_dataset.py's example for detial\n",
    "    band_freq = lr.mel_frequencies(n_mels=nband, fmin=lowfreq, fmax=highfreq)\n",
    "    # band_freq = lr.mel_to_hz(mel_scale)\n",
    "    band_frequency = band_freq[1:-1] # the middle point of each band\n",
    "    print('band frequency', band_frequency)\n",
    "    b, a = iir_design(band_freq, rate, order=1)\n",
    "    step = int(0.020 * rate / 2)\n",
    "    filtered_signal = np.zeros(len(sig))\n",
    "    for i in range(len(b)):\n",
    "        filtered_signal += bandpass_filter_iir(sig, b[i].copy(), a[i].copy(), step, gains[:, i])\n",
    "        print(\"filtering with frequency: \", band_frequency[i])\n",
    "    filtered_signal = filtered_signal * 0.6\n",
    "    return filtered_signal\n",
    "\n",
    "\n",
    "def voice_denoise(sig, rate, model, timestamp_size=512, numcep=26, plot=False):\n",
    "    # sig = sig / 32768\n",
    "    num_diffs = 10\n",
    "    window_length = int(np.round(0.020*rate))\n",
    "    hop_length = int(np.round(0.010*rate))\n",
    "    # get the mfcc of noisy voice\n",
    "    mfcc_feat = lr.feature.mfcc(sig, rate, n_mfcc=numcep, n_fft=512, win_length = window_length, hop_length = hop_length, dct_type=2, lifter=0, fmin=20, fmax=4000)\n",
    "    mfcc_feat = mfcc_feat.astype('float32')\n",
    "    # mfcc_feat = mfcc_feat[:,:3888]\n",
    "    mfcc_feat = mfcc_feat.T\n",
    "    print(\"mfcc_feat.shape: \", mfcc_feat.shape) # (6223, 22)\n",
    "    # differential of mfcc, add 0 to the beginning\n",
    "    diff = np.diff(mfcc_feat, axis=0)\n",
    "    diff = np.concatenate([[mfcc_feat[0]], diff], axis=0)  # first derivative\n",
    "    diff1 = np.diff(diff, axis=0)\n",
    "    diff1 = np.concatenate([[diff[0]], diff1], axis=0) # second derivative\n",
    "    diff = diff[:, :num_diffs]\n",
    "    diff1 = diff1[:, :num_diffs]\n",
    "    # concat both differential and original mfcc\n",
    "    print(\"diff.shape: \", diff.shape)\n",
    "    print(\"diff1.shape: \", diff1.shape)\n",
    "    feat = np.concatenate([mfcc_feat, diff, diff1], axis=-1)\n",
    "    print(\"1feat.shape: \", feat.shape)\n",
    "    # requantise the MFCC (same as training data)\n",
    "    feat = normalize(feat, 3, quantize=False)\n",
    "    print(\"2feat.shape: \", feat.shape)\n",
    "    feat = np.reshape(feat, (feat.shape[0], 1, feat.shape[1])) # \n",
    "    print(\"3feat.shape: \", feat.shape)\n",
    "    feat = feat[: feat.shape[0] // timestamp_size * timestamp_size]\n",
    "    print(\"4feat.shape: \", feat.shape)\n",
    "    prediction = model.predict(feat, batch_size=timestamp_size)\n",
    "    if(type(prediction) is list):\n",
    "        predicted_gains = prediction[0]\n",
    "        predicted_vad = prediction[1]\n",
    "    else:\n",
    "        predicted_gains = prediction\n",
    "        predicted_vad = None\n",
    "\n",
    "    # now process the signal.\n",
    "    print('predicted_gains: ', predicted_gains.shape)\n",
    "    # filtered_sig = filter_voice(sig, rate=rate, gains=predicted_gains, nband=mfcc_feat.shape[-1])\n",
    "    filtered_sig = filter_voice(sig, rate=rate, gains=predicted_gains, nband=24)\n",
    "    if(plot):\n",
    "        plt.figure(figsize=(20, 7))\n",
    "        for i in range(10):\n",
    "            plt.plot(predicted_gains[:, i], label='band'+str(i))\n",
    "        if(predicted_vad is not None):\n",
    "            plt.plot(predicted_vad, 'r', label='VAD')\n",
    "        plt.ylabel(\"Gains\")\n",
    "        plt.xlabel(\"MFCC Sample\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return filtered_sig\n",
    "\n",
    "\n",
    "def stoi_wrapper(ref, denoised, sr, extension = True):\n",
    "    \"\"\"\n",
    "    Computes the intelligibility score based on the STOI predictor.\n",
    "\n",
    "    Based on: C. H. Taal, R. C. Hendriks, R. Heusdens, and J. Jensen, \n",
    "    \"A Short-Time Objective Intelligibility Measure for Time-Frequency Weighted Noisy\n",
    "    Speech\", IEEE Int. Conf. Acoust., Speech, Signal Processing, Dallas, United States,\n",
    "    pp. 4214-4217, 2010.\n",
    "\n",
    "    Signals are resampled to 10kHz by the stoi method if sr != 10000.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ref (1D ndarray): clean signal\n",
    "    denoised (1D ndarray): restored signal, i.e, denoised.\n",
    "    sr (float): sampling frequency \n",
    "    extension (str): True extends the STOI score for non-linearly processed input signals\n",
    "        such as time-frequency masking operations.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float: estimated intelligibility score in [0, 100]\n",
    "\n",
    "\n",
    "    Calls: None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    d = stoi(ref, denoised, sr, extended = extension)\n",
    "    return 100 / (1 + np.exp(-13.1903 * d + 6.5192))\n",
    "\n",
    "\n",
    "def pesq_wrapper(ref, denoised, sr, mode = 'nb'):\n",
    "    \"\"\"\n",
    "    Computes an estimation of the MOS-LQO score based on raw PESQ scores.\n",
    "\n",
    "    The implementation is taken from the github repo pypesq. Sampling frequency \n",
    "    should be either 8k or 16k. It is not consistent with the results provided\n",
    "    by pesq_ITU_wrapper.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ref (1D ndarray): clean signal\n",
    "    denoised (1D ndarray): restored signal, i.e, denoised.\n",
    "    sr (float): sampling frequency; either 8k for narrowband or 16k for wideband\n",
    "    mode (str): either 'nb' or 'wb' for narrow- and wide-band respectively.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float: estimated MOS-LQO score. Rescaling of [-0.5, 4.5] raw MOS scores to \n",
    "        a range of [1.02, 4.56] for MOS-LQO scores.\n",
    "\n",
    "\n",
    "    Calls: None\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    p = pesq(ref, denoised, sr) # Raw scores in [-0.5, 4.5]\n",
    "    # mapping to MOS-LQO\n",
    "    return 0.999 + (4.999 - 0.999) / (1 + np.exp(-1.4945 * p + 4.6607))"
   ]
  },
  {
   "source": [
    "## Load Dataset and prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load training dataset\n",
    "try:\n",
    "    dataset = np.load('dataset.npz', allow_pickle=True)\n",
    "except:\n",
    "    raise Exception(\"Given dataset not found.\")\n",
    "\n",
    "# extract mfcc, vad and gains\n",
    "clnsp_mfcc = dataset['clnsp_mfcc']    # clean speech mfccs\n",
    "noisy_mfcc = dataset['noisy_mfcc']    # noisy speech mfccs\n",
    "vad = dataset['vad']                  # voice activation detection\n",
    "gains = dataset['gains']              # gains\n",
    "# get mfcc derivative from dataset.\n",
    "clnsp_mfcc_diff = get_diff_list(clnsp_mfcc)\n",
    "noisy_mfcc_diff = get_diff_list(noisy_mfcc)\n",
    "clnsp_mfcc_diff1 = get_diff_list(clnsp_mfcc_diff)\n",
    "noisy_mfcc_diff1 = get_diff_list(noisy_mfcc_diff)\n",
    "\n",
    "# combine all pieces to one large array\n",
    "clnsp_mfcc = np.concatenate(clnsp_mfcc, axis=0)\n",
    "noisy_mfcc = np.concatenate(noisy_mfcc, axis=0)\n",
    "clnsp_mfcc_diff = np.concatenate(clnsp_mfcc_diff, axis=0)\n",
    "noisy_mfcc_diff = np.concatenate(noisy_mfcc_diff, axis=0)\n",
    "clnsp_mfcc_diff1 = np.concatenate(clnsp_mfcc_diff1, axis=0)\n",
    "noisy_mfcc_diff1 = np.concatenate(noisy_mfcc_diff1, axis=0)\n",
    "vad = np.concatenate(vad, axis=0)\n",
    "gains = np.concatenate(gains, axis=0)\n",
    "\n",
    "# these max and min are rear\n",
    "print('mfcc max:', noisy_mfcc.max(), 'mfcc min:', noisy_mfcc.min())\n",
    "print('mfcc diff max:', noisy_mfcc_diff.max(), 'mfcc diff min:', noisy_mfcc_diff.min())\n",
    "\n",
    "# preprocess data\n",
    "timestamp_size = 1024 # this must be > than 1024, since we are using 1 sample as a batch, which still too small for BP\n",
    "num_sequence = len(vad) // timestamp_size\n",
    "print('timestamp', timestamp_size, 'num of data', num_sequence)\n",
    "\n",
    "# prepare data\n",
    "diff = np.copy(noisy_mfcc_diff[:num_sequence * timestamp_size, :10])\n",
    "diff1 = np.copy(noisy_mfcc_diff1[:num_sequence * timestamp_size, :10])\n",
    "feat = np.copy(noisy_mfcc[:num_sequence * timestamp_size, :])\n",
    "\n",
    "# concat mfcc, 1st and 2nd derivative together as the training data.\n",
    "x_train = np.concatenate([feat, diff, diff1], axis=-1)\n",
    "# convert MFCC range to -1 to 1.0 In quantization, we will saturate them to leave more resolution in smaller numbers\n",
    "# we saturate the peak to leave some more resolution in other band.\n",
    "x_train = normalize(x_train, 3, quantize=False)\n",
    "\n",
    "# reshape\n",
    "x_train = np.copy(x_train[:num_sequence * timestamp_size, :])\n",
    "x_train = np.reshape(x_train, (num_sequence* timestamp_size, 1, x_train.shape[-1]))\n",
    "y_train = np.copy(gains[:num_sequence * timestamp_size,:])\n",
    "y_train = np.reshape(y_train, (num_sequence* timestamp_size, gains.shape[-1]))\n",
    "vad_train = np.copy(vad[:num_sequence * timestamp_size]).astype(np.float32)\n",
    "vad_train = np.reshape(vad_train, (num_sequence * timestamp_size, 1))\n",
    "print(\"x_train.shape: \", x_train.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"vad_train.shape: \", vad_train.shape)"
   ]
  },
  {
   "source": [
    "## Define Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, y_train, vad_train, batch_size=64, epochs=10, model_name=\"model_new.h5\"):\n",
    "    \"\"\"\n",
    "    RNNoise-like structure with some adaption to fit NNoM's implementation.\n",
    "    \"\"\"\n",
    "    input_feature_size = x_train.shape[-1] # 42\n",
    "    output_feature_size = y_train.shape[-1] # 22\n",
    "    timestamp_size = batch_size # 2048\n",
    "    input = tf.keras.Input(shape=(1, input_feature_size), batch_size=timestamp_size) # (1, 42, 2048)\n",
    "    \n",
    "    \"\"\"\n",
    "        This is an RNNoise-like structure\n",
    "    \"\"\"\n",
    "    # voice activity detection\n",
    "    # x1_1 = tf.keras.layers.GRU(24, return_sequences=True, stateful=True, recurrent_dropout=0.2)(input)\n",
    "    x1_1 = tf.keras.layers.Dense(24, activation=\"tanh\")(input)\n",
    "    # x1_1 = tf.keras.layers.Dropout(0.3)(x1_1)\n",
    "    x1_2 = tf.keras.layers.GRU(24, activation=\"relu\", reset_after=False, return_sequences=True)(x1_1)\n",
    "    # x1_2 = tf.keras.layers.Dropout(0.3)(x1_2)\n",
    "    x = tf.keras.layers.Flatten()(x1_2)\n",
    "    # x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    vad_output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    # vad_output = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "    # we dont concate input with layer output, because the range different will cause quite many quantisation lost.\n",
    "    # x_in = tf.keras.layers.GRU(64, return_sequences=True, stateful=True, recurrent_dropout=0.3)(input)\n",
    "\n",
    "    # Noise spectral estimation\n",
    "    x2 = tf.keras.layers.concatenate([input, x1_1, x1_2], axis=-1)\n",
    "    x2 = tf.keras.layers.GRU(48, activation=\"relu\", reset_after=False, return_sequences=True)(x2)\n",
    "    # x2 = tf.keras.layers.Dropout(0.3)(x2)\n",
    "\n",
    "    #Spectral subtraction\n",
    "    x3 = tf.keras.layers.concatenate([input, x2, x1_2], axis=-1)\n",
    "    x3 = tf.keras.layers.GRU(96, activation=\"relu\", reset_after=False, return_sequences=True)(x3)\n",
    "    # x3 = tf.keras.layers.Dropout(0.3)(x3)\n",
    "    x = tf.keras.layers.Flatten()(x3)\n",
    "    x = tf.keras.layers.Dense(output_feature_size, activation=\"sigmoid\")(x) #output_feature_size\n",
    "    # x = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=[x, vad_output])\n",
    "    model.compile(\"adam\", loss=[mycost, my_crossentropy], loss_weights=[10, 0.5], metrics=[msse])\n",
    "    # model.compile(\"adam\", loss=[\"MSE\", \"binary_crossentropy\"], loss_weights=[10, 2])\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(x_train, [y_train, vad_train], batch_size=timestamp_size, epochs=epochs, verbose=2, shuffle=False)\n",
    "\n",
    "    # free the session to avoid nesting naming while we load the best model after.\n",
    "    tf.keras.models.save_model(model, model_name)\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    return history"
   ]
  },
  {
   "source": [
    "## Train Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# training\n",
    "history = train(x_train, y_train, vad_train, batch_size=timestamp_size, epochs=1, model_name=\"model_new.h5\")\n",
    "\n",
    "# get the best model\n",
    "model = tf.keras.models.load_model(\"model_new.h5\", custom_objects={'mycost': mycost, 'msse': msse, 'my_crossentropy': my_crossentropy, 'my_accuracy': my_accuracy})\n",
    "# model = tf.keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "source": [
    "## Denoise a file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the MFCC parameters inside the voice_denoise() are the same as our gen_dataset.\n",
    "\n",
    "# Load noisy file\n",
    "(sig, rate) = lr.load(\"_noisy_sample.wav\", sr=8000)\n",
    "# sig = np.asarray(sig * 32767, dtype=np.int16)\n",
    "print('min: ', np.min(sig))\n",
    "print('max: ', np.max(sig))\n",
    "print('rate: ', rate)\n",
    "# Denoising\n",
    "filtered_sig = voice_denoise(sig, rate, model, timestamp_size=1, numcep=y_train.shape[-1], plot=True) # use plot=True argument to see the gains/vad\n",
    "filtered_sig = np.asarray(filtered_sig * 32767, dtype=np.int16)\n",
    "# Write denoised file\n",
    "sf.write(\"_nn_filtered_sample_new.wav\", filtered_sig, rate)\n",
    "# sf.write(\"_nn_filtered_sample_inv.wav\", filtered_sig[::-1], rate)\n",
    "# sf.write(\"_clean_sample_inv.wav\", sig[::-1], rate)\n",
    "print('min: ', np.min(filtered_sig))\n",
    "print('max: ', np.max(filtered_sig))"
   ]
  },
  {
   "source": [
    "## Speech Evaluation - Denoised"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, rate) = lr.load(\"_clean_sample.wav\", sr=16000)\n",
    "x = np.asarray(x * 32767, dtype=np.int16)\n",
    "\n",
    "mos_lqo = pysepm.pesq(x, filtered_sig, rate)\n",
    "print('(pesq_mos, mos_lqo): ', mos_lqo)\n",
    "stoi = pysepm.stoi(x, filtered_sig, rate)\n",
    "print('stoi: ', stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd01c636357d238e04e523522b8acb0bb6ffa001402100e45981506eb7e4d01fa95",
   "display_name": "Python 3.8.8 64-bit ('deepns_env': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "1c636357d238e04e523522b8acb0bb6ffa001402100e45981506eb7e4d01fa95"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}