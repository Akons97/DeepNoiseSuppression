{
 "cells": [
  {
   "source": [
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras  import backend as K\n",
    "from tensorflow.keras.models import load_model, save_model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import librosa as lr\n",
    "import soundfile as sf\n",
    "from scipy import signal\n",
    "\n",
    "from pystoi import stoi\n",
    "from pesq import pesq"
   ]
  },
  {
   "source": [
    "## Utility functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_crossentropy(y_true, y_pred):\n",
    "    return K.mean(2*K.abs(y_true-0.5) * K.binary_crossentropy(y_pred, y_true), axis=-1)\n",
    "\n",
    "def mymask(y_true):\n",
    "    return K.minimum(y_true+1., 1.)\n",
    "\n",
    "def msse(y_true, y_pred):\n",
    "    return K.mean(mymask(y_true) * K.square(K.sqrt(y_pred) - K.sqrt(y_true)), axis=-1)\n",
    "\n",
    "def mycost(y_true, y_pred):\n",
    "     return K.mean(mymask(y_true) * (10*K.square(K.square(K.sqrt(y_pred) - K.sqrt(y_true))) + K.square(K.sqrt(y_pred) - K.sqrt(y_true)) + 0.01*K.binary_crossentropy(y_pred, y_true)), axis=-1)\n",
    "\n",
    "def my_accuracy(y_true, y_pred):\n",
    "    return K.mean(2*K.abs(y_true-0.5) * K.equal(y_true, K.round(y_pred)), axis=-1)\n",
    "\n",
    "\n",
    "# list of mfcc differentials, adds 0 to the beginning\n",
    "def get_diff_list(data):\n",
    "    L = []\n",
    "    for d in data:\n",
    "        L.append(np.concatenate([[d[0]], np.diff(d, axis=-2)], axis=-2))\n",
    "    return np.array(L)\n",
    "\n",
    "\n",
    "def normalize(data, n, quantize=True):\n",
    "    limit = pow(2, n)\n",
    "    data = np.clip(data, -limit, limit)/limit\n",
    "    if quantize:\n",
    "        data = np.round(data * 128)/ 128.0\n",
    "    return data\n",
    "\n",
    "\n",
    "def iir_design(band_frequency, samplerate, order=1): # the band frequency is the middle freq\n",
    "    b = []\n",
    "    a = []\n",
    "    fre = band_frequency / (samplerate/2)\n",
    "    for i in range(1, len(band_frequency)-1):\n",
    "        b_, a_ = signal.iirfilter(order, [fre[i] - (fre[i]-fre[i-1])/2, fre[i]+ (fre[i+1]-fre[i])/2], btype='bandpass', output='ba')\n",
    "        b.append(b_)\n",
    "        a.append(a_)\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def bandpass_filter_iir(sig, b_in, a_in, step, gains):\n",
    "    x = sig\n",
    "    y = np.zeros(len(x))\n",
    "    state = np.zeros(len(b_in)-1)\n",
    "    g=0\n",
    "    for n in range(0, len(gains)):\n",
    "        g = max(0.6*g, gains[n])    # r=0.6 pre RNNoise paper https://arxiv.org/pdf/1709.08243.pdf\n",
    "        b = b_in*g\n",
    "        a = a_in\n",
    "        filtered, state = signal.lfilter(b, a, x[n*step: min((n+1)*step, len(x))], zi=state)\n",
    "        y[n*step: min((n+1)*step, len(x))] = filtered\n",
    "    return y\n",
    "\n",
    "\n",
    "def filter_voice(sig, rate, gains, nband=22, lowfreq=20, highfreq=4000):\n",
    "    # see gen_dataset.py's example for detial\n",
    "    band_freq = lr.mel_frequencies(n_mels=nband, fmin=lowfreq, fmax=highfreq)\n",
    "    # band_freq = lr.mel_to_hz(mel_scale)\n",
    "    band_frequency = band_freq[1:-1] # the middle point of each band\n",
    "    print('band frequency', band_frequency)\n",
    "    b, a = iir_design(band_freq, rate, order=1)\n",
    "    step = int(0.020 * rate / 2)\n",
    "    filtered_signal = np.zeros(len(sig))\n",
    "    for i in range(len(b)):\n",
    "        filtered_signal += bandpass_filter_iir(sig, b[i].copy(), a[i].copy(), step, gains[:, i])\n",
    "        print(\"filtering with frequency: \", band_frequency[i])\n",
    "    filtered_signal = filtered_signal * 0.6\n",
    "    return filtered_signal\n",
    "\n",
    "\n",
    "def voice_denoise(sig, rate, model, timestamp_size=512, numcep=26, plot=False):\n",
    "    # sig = sig / 32768\n",
    "    num_diffs = 10\n",
    "    window_length = int(np.round(0.020*rate))\n",
    "    hop_length = int(np.round(0.010*rate))\n",
    "    # get the mfcc of noisy voice\n",
    "    mfcc_feat = lr.feature.mfcc(sig, rate, n_mfcc=numcep, n_fft=512, win_length = window_length, hop_length = hop_length, dct_type=2, lifter=0, fmin=20, fmax=4000)\n",
    "    mfcc_feat = mfcc_feat.astype('float32')\n",
    "    # mfcc_feat = mfcc_feat[:,:3888]\n",
    "    mfcc_feat = mfcc_feat.T\n",
    "    print(\"mfcc_feat.shape: \", mfcc_feat.shape) # (6223, 22)\n",
    "    # differential of mfcc, add 0 to the beginning\n",
    "    diff = np.diff(mfcc_feat, axis=0)\n",
    "    diff = np.concatenate([[mfcc_feat[0]], diff], axis=0)  # first derivative\n",
    "    diff1 = np.diff(diff, axis=0)\n",
    "    diff1 = np.concatenate([[diff[0]], diff1], axis=0) # second derivative\n",
    "    diff = diff[:, :num_diffs]\n",
    "    diff1 = diff1[:, :num_diffs]\n",
    "    # concat both differential and original mfcc\n",
    "    print(\"diff.shape: \", diff.shape)\n",
    "    print(\"diff1.shape: \", diff1.shape)\n",
    "    feat = np.concatenate([mfcc_feat, diff, diff1], axis=-1)\n",
    "    print(\"1feat.shape: \", feat.shape)\n",
    "    # requantise the MFCC (same as training data)\n",
    "    feat = normalize(feat, 3, quantize=False)\n",
    "    print(\"2feat.shape: \", feat.shape)\n",
    "    feat = np.reshape(feat, (feat.shape[0], 1, feat.shape[1])) # \n",
    "    print(\"3feat.shape: \", feat.shape)\n",
    "    feat = feat[: feat.shape[0] // timestamp_size * timestamp_size]\n",
    "    print(\"4feat.shape: \", feat.shape)\n",
    "    prediction = model.predict(feat, batch_size=timestamp_size)\n",
    "    if(type(prediction) is list):\n",
    "        predicted_gains = prediction[0]\n",
    "        predicted_vad = prediction[1]\n",
    "    else:\n",
    "        predicted_gains = prediction\n",
    "        predicted_vad = None\n",
    "\n",
    "    # now process the signal.\n",
    "    print('predicted_gains: ', predicted_gains.shape)\n",
    "    # filtered_sig = filter_voice(sig, rate=rate, gains=predicted_gains, nband=mfcc_feat.shape[-1])\n",
    "    filtered_sig = filter_voice(sig, rate=rate, gains=predicted_gains, nband=24)\n",
    "    if(plot):\n",
    "        plt.figure(figsize=(20, 7))\n",
    "        for i in range(10):\n",
    "            plt.plot(predicted_gains[:, i], label='band'+str(i))\n",
    "        if(predicted_vad is not None):\n",
    "            plt.plot(predicted_vad, 'r', label='VAD')\n",
    "        plt.ylabel(\"Gains\")\n",
    "        plt.xlabel(\"MFCC Sample\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return filtered_sig\n",
    "\n",
    "\n",
    "def stoi_wrapper(ref, denoised, sr, extension = True):\n",
    "    \"\"\"\n",
    "    Computes the intelligibility score based on the STOI predictor.\n",
    "\n",
    "    Based on: C. H. Taal, R. C. Hendriks, R. Heusdens, and J. Jensen, \n",
    "    \"A Short-Time Objective Intelligibility Measure for Time-Frequency Weighted Noisy\n",
    "    Speech\", IEEE Int. Conf. Acoust., Speech, Signal Processing, Dallas, United States,\n",
    "    pp. 4214-4217, 2010.\n",
    "\n",
    "    Signals are resampled to 10kHz by the stoi method if sr != 10000.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ref (1D ndarray): clean signal\n",
    "    denoised (1D ndarray): restored signal, i.e, denoised.\n",
    "    sr (float): sampling frequency \n",
    "    extension (str): True extends the STOI score for non-linearly processed input signals\n",
    "        such as time-frequency masking operations.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float: estimated intelligibility score in [0, 100]\n",
    "\n",
    "\n",
    "    Calls: None\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    d = stoi(ref, denoised, sr, extended = extension)\n",
    "    return 100 / (1 + np.exp(-13.1903 * d + 6.5192))\n",
    "\n",
    "\n",
    "def pesq_wrapper(ref, denoised, sr, mode = 'nb'):\n",
    "    \"\"\"\n",
    "    Computes an estimation of the MOS-LQO score based on raw PESQ scores.\n",
    "\n",
    "    The implementation is taken from the github repo pypesq. Sampling frequency \n",
    "    should be either 8k or 16k. It is not consistent with the results provided\n",
    "    by pesq_ITU_wrapper.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    ref (1D ndarray): clean signal\n",
    "    denoised (1D ndarray): restored signal, i.e, denoised.\n",
    "    sr (float): sampling frequency; either 8k for narrowband or 16k for wideband\n",
    "    mode (str): either 'nb' or 'wb' for narrow- and wide-band respectively.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    float: estimated MOS-LQO score. Rescaling of [-0.5, 4.5] raw MOS scores to \n",
    "        a range of [1.02, 4.56] for MOS-LQO scores.\n",
    "\n",
    "\n",
    "    Calls: None\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    p = pesq(sr, ref, denoised, mode) # Raw scores in [-0.5, 4.5]\n",
    "    # mapping to MOS-LQO\n",
    "    return 0.999 + (4.999 - 0.999) / (1 + np.exp(-1.4945 * p + 4.6607))"
   ]
  },
  {
   "source": [
    "## Load Dataset and prepare data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "mfcc max: 27.341293 mfcc min: -17.184874\n",
      "mfcc diff max: 22.255035 mfcc diff min: -24.103506\n",
      "timestamp 1024 num of data 1025\n",
      "x_train.shape:  (1049600, 1, 42)\n",
      "y_train.shape:  (1049600, 22)\n",
      "vad_train.shape:  (1049600, 1)\n"
     ]
    }
   ],
   "source": [
    "# load training dataset\n",
    "try:\n",
    "    dataset = np.load('dataset.npz', allow_pickle=True)\n",
    "except:\n",
    "    raise Exception(\"Given dataset not found.\")\n",
    "\n",
    "# extract mfcc, vad and gains\n",
    "clnsp_mfcc = dataset['clnsp_mfcc']    # clean speech mfccs\n",
    "noisy_mfcc = dataset['noisy_mfcc']    # noisy speech mfccs\n",
    "vad = dataset['vad']                  # voice activation detection\n",
    "gains = dataset['gains']              # gains\n",
    "# get mfcc derivative from dataset.\n",
    "clnsp_mfcc_diff = get_diff_list(clnsp_mfcc)\n",
    "noisy_mfcc_diff = get_diff_list(noisy_mfcc)\n",
    "clnsp_mfcc_diff1 = get_diff_list(clnsp_mfcc_diff)\n",
    "noisy_mfcc_diff1 = get_diff_list(noisy_mfcc_diff)\n",
    "\n",
    "# combine all pieces to one large array\n",
    "clnsp_mfcc = np.concatenate(clnsp_mfcc, axis=0)\n",
    "noisy_mfcc = np.concatenate(noisy_mfcc, axis=0)\n",
    "clnsp_mfcc_diff = np.concatenate(clnsp_mfcc_diff, axis=0)\n",
    "noisy_mfcc_diff = np.concatenate(noisy_mfcc_diff, axis=0)\n",
    "clnsp_mfcc_diff1 = np.concatenate(clnsp_mfcc_diff1, axis=0)\n",
    "noisy_mfcc_diff1 = np.concatenate(noisy_mfcc_diff1, axis=0)\n",
    "vad = np.concatenate(vad, axis=0)\n",
    "gains = np.concatenate(gains, axis=0)\n",
    "\n",
    "# these max and min are rear\n",
    "print('mfcc max:', noisy_mfcc.max(), 'mfcc min:', noisy_mfcc.min())\n",
    "print('mfcc diff max:', noisy_mfcc_diff.max(), 'mfcc diff min:', noisy_mfcc_diff.min())\n",
    "\n",
    "# preprocess data\n",
    "timestamp_size = 1024 # this must be > than 1024, since we are using 1 sample as a batch, which still too small for BP\n",
    "num_sequence = len(vad) // timestamp_size\n",
    "print('timestamp', timestamp_size, 'num of data', num_sequence)\n",
    "\n",
    "# prepare data\n",
    "diff = np.copy(noisy_mfcc_diff[:num_sequence * timestamp_size, :10])\n",
    "diff1 = np.copy(noisy_mfcc_diff1[:num_sequence * timestamp_size, :10])\n",
    "feat = np.copy(noisy_mfcc[:num_sequence * timestamp_size, :])\n",
    "\n",
    "# concat mfcc, 1st and 2nd derivative together as the training data.\n",
    "x_train = np.concatenate([feat, diff, diff1], axis=-1)\n",
    "# convert MFCC range to -1 to 1.0 In quantization, we will saturate them to leave more resolution in smaller numbers\n",
    "# we saturate the peak to leave some more resolution in other band.\n",
    "x_train = normalize(x_train, 3, quantize=False)\n",
    "\n",
    "# reshape\n",
    "x_train = np.copy(x_train[:num_sequence * timestamp_size, :])\n",
    "x_train = np.reshape(x_train, (num_sequence* timestamp_size, 1, x_train.shape[-1]))\n",
    "y_train = np.copy(gains[:num_sequence * timestamp_size,:])\n",
    "y_train = np.reshape(y_train, (num_sequence* timestamp_size, gains.shape[-1]))\n",
    "vad_train = np.copy(vad[:num_sequence * timestamp_size]).astype(np.float32)\n",
    "vad_train = np.reshape(vad_train, (num_sequence * timestamp_size, 1))\n",
    "print(\"x_train.shape: \", x_train.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"vad_train.shape: \", vad_train.shape)"
   ]
  },
  {
   "source": [
    "## Define Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(x_train, y_train, vad_train, batch_size=64, epochs=10, model_name=\"model_new.h5\"):\n",
    "    \"\"\"\n",
    "    RNNoise-like structure with some adaption to fit NNoM's implementation.\n",
    "    \"\"\"\n",
    "    input_feature_size = x_train.shape[-1] # 42\n",
    "    output_feature_size = y_train.shape[-1] # 22\n",
    "    timestamp_size = batch_size # 2048\n",
    "    input = tf.keras.Input(shape=(1, input_feature_size), batch_size=timestamp_size) # (1, 42, 2048)\n",
    "    \n",
    "    \"\"\"\n",
    "        This is an RNNoise-like structure\n",
    "    \"\"\"\n",
    "    # voice activity detection\n",
    "    # x1_1 = tf.keras.layers.GRU(24, return_sequences=True, stateful=True, recurrent_dropout=0.2)(input)\n",
    "    x1_1 = tf.keras.layers.Dense(24, activation=\"tanh\")(input)\n",
    "    # x1_1 = tf.keras.layers.Dropout(0.3)(x1_1)\n",
    "    x1_2 = tf.keras.layers.GRU(24, activation=\"relu\", reset_after=False, return_sequences=True)(x1_1)\n",
    "    # x1_2 = tf.keras.layers.Dropout(0.3)(x1_2)\n",
    "    x = tf.keras.layers.Flatten()(x1_2)\n",
    "    # x = tf.keras.layers.Dropout(0.3)(x)\n",
    "    vad_output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    # vad_output = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "    # we dont concate input with layer output, because the range different will cause quite many quantisation lost.\n",
    "    # x_in = tf.keras.layers.GRU(64, return_sequences=True, stateful=True, recurrent_dropout=0.3)(input)\n",
    "\n",
    "    # Noise spectral estimation\n",
    "    x2 = tf.keras.layers.concatenate([input, x1_1, x1_2], axis=-1)\n",
    "    x2 = tf.keras.layers.GRU(48, activation=\"relu\", reset_after=False, return_sequences=True)(x2)\n",
    "    # x2 = tf.keras.layers.Dropout(0.3)(x2)\n",
    "\n",
    "    #Spectral subtraction\n",
    "    x3 = tf.keras.layers.concatenate([input, x2, x1_2], axis=-1)\n",
    "    x3 = tf.keras.layers.GRU(96, activation=\"relu\", reset_after=False, return_sequences=True)(x3)\n",
    "    # x3 = tf.keras.layers.Dropout(0.3)(x3)\n",
    "    x = tf.keras.layers.Flatten()(x3)\n",
    "    x = tf.keras.layers.Dense(output_feature_size, activation=\"sigmoid\")(x) #output_feature_size\n",
    "    # x = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.Model(inputs=input, outputs=[x, vad_output])\n",
    "    model.compile(\"adam\", loss=[mycost, my_crossentropy], loss_weights=[10, 0.5], metrics=[msse])\n",
    "    # model.compile(\"adam\", loss=[\"MSE\", \"binary_crossentropy\"], loss_weights=[10, 2])\n",
    "    model.summary()\n",
    "\n",
    "    history = model.fit(x_train, [y_train, vad_train], batch_size=timestamp_size, epochs=epochs, verbose=2, shuffle=False)\n",
    "\n",
    "    # free the session to avoid nesting naming while we load the best model after.\n",
    "    tf.keras.models.save_model(model, model_name)\n",
    "    del model\n",
    "    K.clear_session()\n",
    "    return history"
   ]
  },
  {
   "source": [
    "## Train Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(1024, 1, 42)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (1024, 1, 24)        1032        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru (GRU)                       (1024, 1, 24)        3528        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (1024, 1, 90)        0           input_1[0][0]                    \n",
      "                                                                 dense[0][0]                      \n",
      "                                                                 gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     (1024, 1, 48)        20016       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (1024, 1, 114)       0           input_1[0][0]                    \n",
      "                                                                 gru_1[0][0]                      \n",
      "                                                                 gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "gru_2 (GRU)                     (1024, 1, 96)        60768       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (1024, 96)           0           gru_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (1024, 24)           0           gru[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (1024, 22)           2134        flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (1024, 1)            25          flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 87,503\n",
      "Trainable params: 87,503\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "1025/1025 - 7s - loss: 3.5683 - dense_2_loss: 0.1031 - dense_1_loss: 5.0746 - dense_2_msse: 0.0378 - dense_1_msse: 0.3039\n",
      "Epoch 2/50\n",
      "1025/1025 - 7s - loss: 2.9811 - dense_2_loss: 0.0564 - dense_1_loss: 4.8340 - dense_2_msse: 0.0227 - dense_1_msse: 0.3128\n",
      "Epoch 3/50\n",
      "1025/1025 - 7s - loss: 2.9126 - dense_2_loss: 0.0498 - dense_1_loss: 4.8300 - dense_2_msse: 0.0203 - dense_1_msse: 0.3128\n",
      "Epoch 4/50\n",
      "1025/1025 - 7s - loss: 2.8767 - dense_2_loss: 0.0462 - dense_1_loss: 4.8287 - dense_2_msse: 0.0191 - dense_1_msse: 0.3128\n",
      "Epoch 5/50\n",
      "1025/1025 - 7s - loss: 2.8522 - dense_2_loss: 0.0438 - dense_1_loss: 4.8280 - dense_2_msse: 0.0182 - dense_1_msse: 0.3128\n",
      "Epoch 6/50\n",
      "1025/1025 - 8s - loss: 2.8341 - dense_2_loss: 0.0420 - dense_1_loss: 4.8275 - dense_2_msse: 0.0176 - dense_1_msse: 0.3128\n",
      "Epoch 7/50\n",
      "1025/1025 - 7s - loss: 2.8195 - dense_2_loss: 0.0406 - dense_1_loss: 4.8271 - dense_2_msse: 0.0171 - dense_1_msse: 0.3128\n",
      "Epoch 8/50\n",
      "1025/1025 - 7s - loss: 2.7708 - dense_2_loss: 0.0396 - dense_1_loss: 4.7495 - dense_2_msse: 0.0167 - dense_1_msse: 0.3011\n",
      "Epoch 9/50\n",
      "1025/1025 - 7s - loss: 2.0091 - dense_2_loss: 0.0399 - dense_1_loss: 3.2197 - dense_2_msse: 0.0168 - dense_1_msse: 0.1508\n",
      "Epoch 10/50\n",
      "1025/1025 - 7s - loss: 1.5946 - dense_2_loss: 0.0391 - dense_1_loss: 2.4080 - dense_2_msse: 0.0164 - dense_1_msse: 0.1122\n",
      "Epoch 11/50\n",
      "1025/1025 - 7s - loss: 1.4947 - dense_2_loss: 0.0379 - dense_1_loss: 2.2316 - dense_2_msse: 0.0160 - dense_1_msse: 0.1124\n",
      "Epoch 12/50\n",
      "1025/1025 - 7s - loss: 1.4583 - dense_2_loss: 0.0371 - dense_1_loss: 2.1749 - dense_2_msse: 0.0157 - dense_1_msse: 0.1132\n",
      "Epoch 13/50\n",
      "1025/1025 - 7s - loss: 1.4339 - dense_2_loss: 0.0364 - dense_1_loss: 2.1388 - dense_2_msse: 0.0155 - dense_1_msse: 0.1136\n",
      "Epoch 14/50\n",
      "1025/1025 - 7s - loss: 1.4151 - dense_2_loss: 0.0359 - dense_1_loss: 2.1117 - dense_2_msse: 0.0153 - dense_1_msse: 0.1137\n",
      "Epoch 15/50\n",
      "1025/1025 - 7s - loss: 1.3992 - dense_2_loss: 0.0355 - dense_1_loss: 2.0888 - dense_2_msse: 0.0152 - dense_1_msse: 0.1136\n",
      "Epoch 16/50\n",
      "1025/1025 - 7s - loss: 1.3847 - dense_2_loss: 0.0351 - dense_1_loss: 2.0678 - dense_2_msse: 0.0150 - dense_1_msse: 0.1132\n",
      "Epoch 17/50\n",
      "1025/1025 - 7s - loss: 1.3709 - dense_2_loss: 0.0347 - dense_1_loss: 2.0471 - dense_2_msse: 0.0149 - dense_1_msse: 0.1126\n",
      "Epoch 18/50\n",
      "1025/1025 - 7s - loss: 1.3565 - dense_2_loss: 0.0344 - dense_1_loss: 2.0242 - dense_2_msse: 0.0148 - dense_1_msse: 0.1115\n",
      "Epoch 19/50\n",
      "1025/1025 - 7s - loss: 1.3408 - dense_2_loss: 0.0342 - dense_1_loss: 1.9981 - dense_2_msse: 0.0147 - dense_1_msse: 0.1101\n",
      "Epoch 20/50\n",
      "1025/1025 - 7s - loss: 1.3263 - dense_2_loss: 0.0339 - dense_1_loss: 1.9746 - dense_2_msse: 0.0146 - dense_1_msse: 0.1090\n",
      "Epoch 21/50\n",
      "1025/1025 - 7s - loss: 1.3144 - dense_2_loss: 0.0336 - dense_1_loss: 1.9559 - dense_2_msse: 0.0145 - dense_1_msse: 0.1084\n",
      "Epoch 22/50\n",
      "1025/1025 - 7s - loss: 1.3045 - dense_2_loss: 0.0334 - dense_1_loss: 1.9411 - dense_2_msse: 0.0144 - dense_1_msse: 0.1080\n",
      "Epoch 23/50\n",
      "1025/1025 - 7s - loss: 1.2959 - dense_2_loss: 0.0332 - dense_1_loss: 1.9287 - dense_2_msse: 0.0143 - dense_1_msse: 0.1078\n",
      "Epoch 24/50\n",
      "1025/1025 - 7s - loss: 1.2882 - dense_2_loss: 0.0329 - dense_1_loss: 1.9178 - dense_2_msse: 0.0143 - dense_1_msse: 0.1076\n",
      "Epoch 25/50\n",
      "1025/1025 - 7s - loss: 1.2816 - dense_2_loss: 0.0327 - dense_1_loss: 1.9085 - dense_2_msse: 0.0142 - dense_1_msse: 0.1075\n",
      "Epoch 26/50\n",
      "1025/1025 - 7s - loss: 1.2757 - dense_2_loss: 0.0325 - dense_1_loss: 1.9004 - dense_2_msse: 0.0141 - dense_1_msse: 0.1074\n",
      "Epoch 27/50\n",
      "1025/1025 - 7s - loss: 1.2701 - dense_2_loss: 0.0324 - dense_1_loss: 1.8928 - dense_2_msse: 0.0141 - dense_1_msse: 0.1073\n",
      "Epoch 28/50\n",
      "1025/1025 - 7s - loss: 1.2649 - dense_2_loss: 0.0322 - dense_1_loss: 1.8857 - dense_2_msse: 0.0140 - dense_1_msse: 0.1072\n",
      "Epoch 29/50\n",
      "1025/1025 - 7s - loss: 1.2600 - dense_2_loss: 0.0320 - dense_1_loss: 1.8791 - dense_2_msse: 0.0139 - dense_1_msse: 0.1071\n",
      "Epoch 30/50\n",
      "1025/1025 - 7s - loss: 1.2554 - dense_2_loss: 0.0319 - dense_1_loss: 1.8728 - dense_2_msse: 0.0139 - dense_1_msse: 0.1070\n",
      "Epoch 31/50\n",
      "1025/1025 - 7s - loss: 1.2511 - dense_2_loss: 0.0318 - dense_1_loss: 1.8668 - dense_2_msse: 0.0138 - dense_1_msse: 0.1070\n",
      "Epoch 32/50\n",
      "1025/1025 - 7s - loss: 1.2469 - dense_2_loss: 0.0316 - dense_1_loss: 1.8610 - dense_2_msse: 0.0138 - dense_1_msse: 0.1069\n",
      "Epoch 33/50\n",
      "1025/1025 - 7s - loss: 1.2429 - dense_2_loss: 0.0315 - dense_1_loss: 1.8557 - dense_2_msse: 0.0137 - dense_1_msse: 0.1068\n",
      "Epoch 34/50\n",
      "1025/1025 - 7s - loss: 1.2392 - dense_2_loss: 0.0314 - dense_1_loss: 1.8505 - dense_2_msse: 0.0137 - dense_1_msse: 0.1067\n",
      "Epoch 35/50\n",
      "1025/1025 - 7s - loss: 1.2356 - dense_2_loss: 0.0313 - dense_1_loss: 1.8457 - dense_2_msse: 0.0137 - dense_1_msse: 0.1066\n",
      "Epoch 36/50\n",
      "1025/1025 - 7s - loss: 1.2323 - dense_2_loss: 0.0312 - dense_1_loss: 1.8411 - dense_2_msse: 0.0136 - dense_1_msse: 0.1065\n",
      "Epoch 37/50\n",
      "1025/1025 - 7s - loss: 1.2290 - dense_2_loss: 0.0311 - dense_1_loss: 1.8367 - dense_2_msse: 0.0136 - dense_1_msse: 0.1065\n",
      "Epoch 38/50\n",
      "1025/1025 - 7s - loss: 1.2260 - dense_2_loss: 0.0310 - dense_1_loss: 1.8326 - dense_2_msse: 0.0136 - dense_1_msse: 0.1064\n",
      "Epoch 39/50\n",
      "1025/1025 - 7s - loss: 1.2231 - dense_2_loss: 0.0309 - dense_1_loss: 1.8288 - dense_2_msse: 0.0135 - dense_1_msse: 0.1064\n",
      "Epoch 40/50\n",
      "1025/1025 - 7s - loss: 1.2204 - dense_2_loss: 0.0308 - dense_1_loss: 1.8252 - dense_2_msse: 0.0135 - dense_1_msse: 0.1063\n",
      "Epoch 41/50\n",
      "1025/1025 - 7s - loss: 1.2178 - dense_2_loss: 0.0307 - dense_1_loss: 1.8217 - dense_2_msse: 0.0135 - dense_1_msse: 0.1063\n",
      "Epoch 42/50\n",
      "1025/1025 - 7s - loss: 1.2154 - dense_2_loss: 0.0306 - dense_1_loss: 1.8184 - dense_2_msse: 0.0134 - dense_1_msse: 0.1063\n",
      "Epoch 43/50\n",
      "1025/1025 - 7s - loss: 1.2129 - dense_2_loss: 0.0305 - dense_1_loss: 1.8152 - dense_2_msse: 0.0134 - dense_1_msse: 0.1062\n",
      "Epoch 44/50\n",
      "1025/1025 - 7s - loss: 1.2106 - dense_2_loss: 0.0305 - dense_1_loss: 1.8122 - dense_2_msse: 0.0134 - dense_1_msse: 0.1062\n",
      "Epoch 45/50\n",
      "1025/1025 - 7s - loss: 1.2085 - dense_2_loss: 0.0304 - dense_1_loss: 1.8094 - dense_2_msse: 0.0133 - dense_1_msse: 0.1062\n",
      "Epoch 46/50\n",
      "1025/1025 - 7s - loss: 1.2064 - dense_2_loss: 0.0303 - dense_1_loss: 1.8066 - dense_2_msse: 0.0133 - dense_1_msse: 0.1062\n",
      "Epoch 47/50\n",
      "1025/1025 - 7s - loss: 1.2044 - dense_2_loss: 0.0302 - dense_1_loss: 1.8041 - dense_2_msse: 0.0133 - dense_1_msse: 0.1062\n",
      "Epoch 48/50\n",
      "1025/1025 - 7s - loss: 1.2024 - dense_2_loss: 0.0302 - dense_1_loss: 1.8016 - dense_2_msse: 0.0133 - dense_1_msse: 0.1061\n",
      "Epoch 49/50\n",
      "1025/1025 - 7s - loss: 1.2005 - dense_2_loss: 0.0301 - dense_1_loss: 1.7990 - dense_2_msse: 0.0132 - dense_1_msse: 0.1061\n",
      "Epoch 50/50\n",
      "1025/1025 - 7s - loss: 1.1987 - dense_2_loss: 0.0300 - dense_1_loss: 1.7965 - dense_2_msse: 0.0132 - dense_1_msse: 0.1061\n",
      "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer gru_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "history = train(x_train, y_train, vad_train, batch_size=timestamp_size, epochs=50, model_name=\"model_new.h5\")\n",
    "\n",
    "# get the best model\n",
    "model = tf.keras.models.load_model(\"model_new.h5\", custom_objects={'mycost': mycost, 'msse': msse, 'my_crossentropy': my_crossentropy, 'my_accuracy': my_accuracy})\n",
    "# model = tf.keras.models.load_model(\"model.h5\")"
   ]
  },
  {
   "source": [
    "## Denoise a file"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "min:  -0.75931174\n",
      "max:  0.62397695\n",
      "rate:  8000\n",
      "mfcc_feat.shape:  (1707, 22)\n",
      "diff.shape:  (1707, 10)\n",
      "diff1.shape:  (1707, 10)\n",
      "1feat.shape:  (1707, 42)\n",
      "2feat.shape:  (1707, 42)\n",
      "3feat.shape:  (1707, 1, 42)\n",
      "4feat.shape:  (1707, 1, 42)\n",
      "predicted_gains:  (1707, 22)\n",
      "band frequency [ 112.97002751  205.94005501  298.91008252  391.88011002  484.85013753\n",
      "  577.82016503  670.79019254  763.76022005  856.73024755  949.70027506\n",
      " 1044.9874619  1150.1388874  1265.87113102 1393.24888317 1533.44396826\n",
      " 1687.74612504 1857.57487169 2044.49256482 2250.2187725  2476.64609362\n",
      " 2725.85756906 3000.14584479 3302.03426333 3634.3000775 ]\n",
      "filtering with frequency:  112.97002750564441\n",
      "filtering with frequency:  205.9400550112888\n",
      "filtering with frequency:  298.9100825169332\n",
      "filtering with frequency:  391.8801100225776\n",
      "filtering with frequency:  484.850137528222\n",
      "filtering with frequency:  577.8201650338665\n",
      "filtering with frequency:  670.7901925395109\n",
      "filtering with frequency:  763.7602200451553\n",
      "filtering with frequency:  856.7302475507996\n",
      "filtering with frequency:  949.7002750564441\n",
      "filtering with frequency:  1044.987461900545\n",
      "filtering with frequency:  1150.138887396307\n",
      "filtering with frequency:  1265.8711310233036\n",
      "filtering with frequency:  1393.2488831725454\n",
      "filtering with frequency:  1533.4439682595225\n",
      "filtering with frequency:  1687.7461250405315\n",
      "filtering with frequency:  1857.57487169381\n",
      "filtering with frequency:  2044.4925648194917\n",
      "filtering with frequency:  2250.2187724959585\n",
      "filtering with frequency:  2476.646093618968\n",
      "filtering with frequency:  2725.8575690551484\n",
      "filtering with frequency:  3000.145844785522\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "IndexError",
     "evalue": "index 22 is out of bounds for axis 1 with size 22",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8bb7b8d9b670>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rate: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Denoising\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mfiltered_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvoice_denoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimestamp_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumcep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# use plot=True argument to see the gains/vad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mfiltered_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_sig\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m32767\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Write denoised file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-769a575e0192>\u001b[0m in \u001b[0;36mvoice_denoise\u001b[0;34m(sig, rate, model, timestamp_size, numcep, plot)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'predicted_gains: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_gains\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;31m# filtered_sig = filter_voice(sig, rate=rate, gains=predicted_gains, nband=mfcc_feat.shape[-1])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mfiltered_sig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_voice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgains\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredicted_gains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnband\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m26\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-29-769a575e0192>\u001b[0m in \u001b[0;36mfilter_voice\u001b[0;34m(sig, rate, gains, nband, lowfreq, highfreq)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mfiltered_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mfiltered_signal\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbandpass_filter_iir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgains\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"filtering with frequency: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mband_frequency\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mfiltered_signal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_signal\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 22 is out of bounds for axis 1 with size 22"
     ]
    }
   ],
   "source": [
    "# Make sure the MFCC parameters inside the voice_denoise() are the same as our gen_dataset.\n",
    "\n",
    "# Load noisy file\n",
    "(sig, rate) = lr.load(\"_noisy_sample.wav\", sr=8000)\n",
    "# sig = np.asarray(sig * 32767, dtype=np.int16)\n",
    "print('min: ', np.min(sig))\n",
    "print('max: ', np.max(sig))\n",
    "print('rate: ', rate)\n",
    "# Denoising\n",
    "filtered_sig = voice_denoise(sig, rate, model, timestamp_size=1, numcep=y_train.shape[-1], plot=True) # use plot=True argument to see the gains/vad\n",
    "filtered_sig = np.asarray(filtered_sig * 32767, dtype=np.int16)\n",
    "# Write denoised file\n",
    "sf.write(\"_nn_filtered_sample_new.wav\", filtered_sig, rate)\n",
    "# sf.write(\"_nn_filtered_sample_inv.wav\", filtered_sig[::-1], rate)\n",
    "# sf.write(\"_clean_sample_inv.wav\", sig[::-1], rate)\n",
    "print('min: ', np.min(filtered_sig))\n",
    "print('max: ', np.max(filtered_sig))"
   ]
  },
  {
   "source": [
    "## Speech Evaluation - Denoised"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-6a884b9e95b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmos_lqo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpesq_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenoised\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiltered_sig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mstoi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstoi_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenoised\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiltered_sig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mos_lqo: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmos_lqo\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 1.4281256460921785\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stoi: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstoi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 62.942086539244094\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-2a3a349dabcc>\u001b[0m in \u001b[0;36mstoi_wrapper\u001b[0;34m(ref, denoised, sr, extension)\u001b[0m\n\u001b[1;32m    154\u001b[0m     \"\"\"\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m     \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstoi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenoised\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m13.1903\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m6.5192\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "(x, rate) = lr.load(\"_clean_sample.wav\", sr=16000)\n",
    "x = np.asarray(x * 32767, dtype=np.int16)\n",
    "\n",
    "mos_lqo = pesq_wrapper(ref=x, denoised=filtered_sig, sr=rate)\n",
    "stoi = stoi_wrapper(ref=x, denoised=filtered_sig, sr=rate)\n",
    "print('mos_lqo: ', mos_lqo) # 1.4281256460921785\n",
    "print('stoi: ', stoi) # 62.942086539244094"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}